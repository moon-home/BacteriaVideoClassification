{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Concatenate\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, History, Callback\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSplit(x_total_addr, y_total_addr, val_ratio = 0.2):\n",
    "    x_total = np.load(x_total_addr)\n",
    "    y_total = np.load(y_total_addr)\n",
    "    idx_shuffle = np.array(range(x_total.shape[0]))\n",
    "    np.random.shuffle(idx_shuffle)\n",
    "    idx_train = idx_shuffle[:int(x_total.shape[0]*0.8)]\n",
    "    idx_val = idx_shuffle[int(x_total.shape[0]*0.8):]\n",
    "    x_train = x_total[idx_train]\n",
    "    y_train = y_total[idx_train]\n",
    "    x_val = x_total[idx_val]\n",
    "    y_val = y_total[idx_val]\n",
    "    print(\"x_total:\", x_total.shape, \"\\ny_total:\", y_total.shape, \n",
    "          \"\\nx_train length:\", x_train.shape, \"\\ny_train length:\", y_train.shape, \n",
    "          \"\\nx_val length:\", x_val.shape, \"\\ny_val length:\", y_val.shape)\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_total: (1775, 26) \n",
      "y_total: (1775,) \n",
      "x_train length: (1420, 26) \n",
      "y_train length: (1420,) \n",
      "x_val length: (355, 26) \n",
      "y_val length: (355,)\n"
     ]
    }
   ],
   "source": [
    "x_addr = os.path.join(\"npy\", \"26feature\", \"x_total.npy\")\n",
    "y_addr = os.path.join(\"npy\", \"26feature\", \"y_total.npy\")\n",
    "x_train, y_train, x_val, y_val = DataSplit(x_addr, y_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue Ma\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420 samples, validate on 355 samples\n",
      "Epoch 1/500\n",
      "1420/1420 [==============================] - 1s 789us/step - loss: 9.7683 - sparse_categorical_accuracy: 0.3197 - val_loss: 4.8589 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.85886, saving model to checkpoints\\001-0.699.hdf5\n",
      "Epoch 2/500\n",
      "1420/1420 [==============================] - 0s 326us/step - loss: 6.3907 - sparse_categorical_accuracy: 0.5585 - val_loss: 4.8582 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.85886 to 4.85819, saving model to checkpoints\\002-0.699.hdf5\n",
      "Epoch 3/500\n",
      "1420/1420 [==============================] - 0s 336us/step - loss: 5.3610 - sparse_categorical_accuracy: 0.6373 - val_loss: 4.8582 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.85819 to 4.85819, saving model to checkpoints\\003-0.699.hdf5\n",
      "Epoch 4/500\n",
      "1420/1420 [==============================] - 1s 365us/step - loss: 4.9528 - sparse_categorical_accuracy: 0.6782 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.85819 to 4.85815, saving model to checkpoints\\004-0.699.hdf5\n",
      "Epoch 5/500\n",
      "1420/1420 [==============================] - 0s 310us/step - loss: 4.8482 - sparse_categorical_accuracy: 0.6923 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.85815 to 4.85813, saving model to checkpoints\\005-0.699.hdf5\n",
      "Epoch 6/500\n",
      "1420/1420 [==============================] - 0s 347us/step - loss: 4.8699 - sparse_categorical_accuracy: 0.6944 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.85813 to 4.85813, saving model to checkpoints\\006-0.699.hdf5\n",
      "Epoch 7/500\n",
      "1420/1420 [==============================] - 0s 313us/step - loss: 4.8756 - sparse_categorical_accuracy: 0.6937 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.85813\n",
      "Epoch 8/500\n",
      "1420/1420 [==============================] - 0s 338us/step - loss: 4.7828 - sparse_categorical_accuracy: 0.6979 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.85813\n",
      "Epoch 9/500\n",
      "1420/1420 [==============================] - 0s 293us/step - loss: 4.7499 - sparse_categorical_accuracy: 0.7035 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.85813\n",
      "Epoch 10/500\n",
      "1420/1420 [==============================] - 0s 319us/step - loss: 4.7609 - sparse_categorical_accuracy: 0.7014 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.85813\n",
      "Epoch 11/500\n",
      "1420/1420 [==============================] - 0s 341us/step - loss: 4.7068 - sparse_categorical_accuracy: 0.7049 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.85813\n",
      "Epoch 12/500\n",
      "1420/1420 [==============================] - 0s 327us/step - loss: 4.7249 - sparse_categorical_accuracy: 0.7056 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.85813\n",
      "Epoch 13/500\n",
      "1420/1420 [==============================] - 0s 342us/step - loss: 4.7813 - sparse_categorical_accuracy: 0.7021 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.85813\n",
      "Epoch 14/500\n",
      "1420/1420 [==============================] - 0s 326us/step - loss: 4.7139 - sparse_categorical_accuracy: 0.7042 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.85813\n",
      "Epoch 15/500\n",
      "1420/1420 [==============================] - 0s 310us/step - loss: 4.7540 - sparse_categorical_accuracy: 0.7042 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.85813\n",
      "Epoch 16/500\n",
      "1420/1420 [==============================] - 0s 329us/step - loss: 4.7354 - sparse_categorical_accuracy: 0.7049 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.85813\n",
      "Epoch 17/500\n",
      "1420/1420 [==============================] - 0s 300us/step - loss: 4.7076 - sparse_categorical_accuracy: 0.7063 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.85813\n",
      "Epoch 18/500\n",
      "1420/1420 [==============================] - 0s 325us/step - loss: 4.6660 - sparse_categorical_accuracy: 0.7077 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.85813\n",
      "Epoch 19/500\n",
      "1420/1420 [==============================] - 0s 295us/step - loss: 4.7087 - sparse_categorical_accuracy: 0.7042 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.85813\n",
      "Epoch 20/500\n",
      "1420/1420 [==============================] - 0s 319us/step - loss: 4.7061 - sparse_categorical_accuracy: 0.7042 - val_loss: 4.8581 - val_sparse_categorical_accuracy: 0.6986\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.85813\n",
      "Epoch 21/500\n",
      "1420/1420 [==============================] - 0s 312us/step - loss: 3.7799 - sparse_categorical_accuracy: 0.7366 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.85813 to 2.31556, saving model to checkpoints\\021-0.856.hdf5\n",
      "Epoch 22/500\n",
      "1420/1420 [==============================] - 0s 307us/step - loss: 3.1656 - sparse_categorical_accuracy: 0.7845 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.31556\n",
      "Epoch 23/500\n",
      "1420/1420 [==============================] - 0s 320us/step - loss: 2.9379 - sparse_categorical_accuracy: 0.7951 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.31556\n",
      "Epoch 24/500\n",
      "1420/1420 [==============================] - 0s 307us/step - loss: 2.9133 - sparse_categorical_accuracy: 0.8042 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.31556\n",
      "Epoch 25/500\n",
      "1420/1420 [==============================] - 0s 309us/step - loss: 2.7978 - sparse_categorical_accuracy: 0.8211 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.31556\n",
      "Epoch 26/500\n",
      "1420/1420 [==============================] - 0s 324us/step - loss: 2.8151 - sparse_categorical_accuracy: 0.8183 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.31556\n",
      "Epoch 27/500\n",
      "1420/1420 [==============================] - 0s 323us/step - loss: 2.7771 - sparse_categorical_accuracy: 0.8197 - val_loss: 2.3157 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.31556\n",
      "Epoch 28/500\n",
      "1420/1420 [==============================] - 0s 345us/step - loss: 2.7515 - sparse_categorical_accuracy: 0.8225 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.31556\n",
      "Epoch 29/500\n",
      "1420/1420 [==============================] - 0s 327us/step - loss: 2.7229 - sparse_categorical_accuracy: 0.8239 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.31556\n",
      "Epoch 30/500\n",
      "1420/1420 [==============================] - 0s 332us/step - loss: 2.7157 - sparse_categorical_accuracy: 0.8268 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.31556\n",
      "Epoch 31/500\n",
      "1420/1420 [==============================] - 0s 303us/step - loss: 2.7324 - sparse_categorical_accuracy: 0.8261 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.31556\n",
      "Epoch 32/500\n",
      "1420/1420 [==============================] - 0s 345us/step - loss: 2.7535 - sparse_categorical_accuracy: 0.8282 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.31556\n",
      "Epoch 33/500\n",
      "1420/1420 [==============================] - 0s 307us/step - loss: 2.7665 - sparse_categorical_accuracy: 0.8225 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.31556\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 320us/step - loss: 2.7223 - sparse_categorical_accuracy: 0.8289 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.31556\n",
      "Epoch 35/500\n",
      "1420/1420 [==============================] - 1s 395us/step - loss: 2.7532 - sparse_categorical_accuracy: 0.8254 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.31556\n",
      "Epoch 36/500\n",
      "1420/1420 [==============================] - 0s 324us/step - loss: 2.7091 - sparse_categorical_accuracy: 0.8289 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.31556\n",
      "Epoch 37/500\n",
      "1420/1420 [==============================] - 0s 336us/step - loss: 2.7142 - sparse_categorical_accuracy: 0.8303 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.31556\n",
      "Epoch 38/500\n",
      "1420/1420 [==============================] - 0s 347us/step - loss: 2.6935 - sparse_categorical_accuracy: 0.8317 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.31556\n",
      "Epoch 39/500\n",
      "1420/1420 [==============================] - 0s 317us/step - loss: 2.7082 - sparse_categorical_accuracy: 0.8275 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.31556\n",
      "Epoch 40/500\n",
      "1420/1420 [==============================] - 0s 318us/step - loss: 2.7022 - sparse_categorical_accuracy: 0.8289 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.31556\n",
      "Epoch 41/500\n",
      "1420/1420 [==============================] - 1s 373us/step - loss: 2.6941 - sparse_categorical_accuracy: 0.8324 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.8563\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.31556\n"
     ]
    }
   ],
   "source": [
    "########### Naive MLP ############\n",
    "n_feature = x_train.shape[1] #26\n",
    "n_classes = len(np.unique(y_train)) #5\n",
    "\n",
    "Initializer=keras.initializers.glorot_normal(seed=None)\n",
    "######################################## Model architecture ##############################################\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=n_feature, kernel_initializer = Initializer))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, kernel_initializer = Initializer))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_classes, activation='softmax', kernel_initializer = Initializer))\n",
    "######################################## Helpers in callbacks ##############################################\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "######################################## Helpers in callbacks ##############################################\n",
    "tb = TensorBoard(log_dir=os.path.join('tensorboard', 'logs',))\n",
    "early_stopper = EarlyStopping(patience=20)\n",
    "csv_logger = CSVLogger(os.path.join('logs', str(time.time()) + '.log'))\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join('checkpoints','{epoch:03d}-{val_sparse_categorical_accuracy:.3f}.hdf5'),\n",
    "                                verbose=1,save_best_only=True)\n",
    "history=History()\n",
    "#########################################################################################################\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=8, nb_epoch=500,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tb, early_stopper, csv_logger, checkpointer, history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_categorical_accuracy: 85.63%\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"best.hdf5\")\n",
    "loaded_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "score = loaded_model.evaluate(x_val, y_val, verbose=0, batch_size = 8)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        37\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.77      1.00      0.87       168\n",
      "           3       1.00      1.00      1.00        80\n",
      "           4       1.00      1.00      1.00        56\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       355\n",
      "   macro avg       0.55      0.60      0.57       355\n",
      "weighted avg       0.75      0.86      0.79       355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue Ma\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(x_val)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['sparse_categorical_accuracy'])\n",
    "pyplot.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_train)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
