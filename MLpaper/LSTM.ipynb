{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Concatenate\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, History\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSplit(x_total_addr, y_total_addr, val_ratio = 0.2):\n",
    "    x_total = np.load(x_total_addr)\n",
    "    y_total = np.load(y_total_addr)\n",
    "    index_split = int(x_total.shape[0]*0.8)\n",
    "    x_train = x_total[:index_split]\n",
    "    y_train = y_total[:index_split]\n",
    "    x_val = x_total[index_split:]\n",
    "    y_val = y_total[index_split:]\n",
    "    print(\"x_total: \", x_total.shape, \"y_total: \", y_total.shape, \n",
    "          \"x_train length: \", x_train.shape, \"y_train length: \", y_train.shape, \n",
    "          \"x_val length: \", x_val.shape, \"y_val length: \", y_val.shape)\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_total:  (5103, 60, 2) y_total:  (5103,) x_train length:  (4082, 60, 2) y_train length:  (4082,) x_val length:  (1021, 60, 2) y_val length:  (1021,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue Ma\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:31: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4082 samples, validate on 1021 samples\n",
      "Epoch 1/100\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 1.5521 - sparse_categorical_accuracy: 0.2974 - val_loss: 1.5175 - val_sparse_categorical_accuracy: 0.3428\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51749, saving model to checkpoints\\001-0.343.hdf5\n",
      "Epoch 2/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4964 - sparse_categorical_accuracy: 0.3481 - val_loss: 1.4562 - val_sparse_categorical_accuracy: 0.3643\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.51749 to 1.45616, saving model to checkpoints\\002-0.364.hdf5\n",
      "Epoch 3/100\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 1.4659 - sparse_categorical_accuracy: 0.3520 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.3898\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.45616 to 1.44381, saving model to checkpoints\\003-0.390.hdf5\n",
      "Epoch 4/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4564 - sparse_categorical_accuracy: 0.3640 - val_loss: 1.4199 - val_sparse_categorical_accuracy: 0.3908\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.44381 to 1.41992, saving model to checkpoints\\004-0.391.hdf5\n",
      "Epoch 5/100\n",
      "4082/4082 [==============================] - 11s 3ms/step - loss: 1.4359 - sparse_categorical_accuracy: 0.3707 - val_loss: 1.4147 - val_sparse_categorical_accuracy: 0.4025\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.41992 to 1.41473, saving model to checkpoints\\005-0.403.hdf5\n",
      "Epoch 6/100\n",
      "4082/4082 [==============================] - 11s 3ms/step - loss: 1.4325 - sparse_categorical_accuracy: 0.3702 - val_loss: 1.4103 - val_sparse_categorical_accuracy: 0.4006\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.41473 to 1.41034, saving model to checkpoints\\006-0.401.hdf5\n",
      "Epoch 7/100\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.4316 - sparse_categorical_accuracy: 0.3765 - val_loss: 1.4257 - val_sparse_categorical_accuracy: 0.3879\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.41034\n",
      "Epoch 8/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4114 - sparse_categorical_accuracy: 0.3849 - val_loss: 1.3978 - val_sparse_categorical_accuracy: 0.4035\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.41034 to 1.39782, saving model to checkpoints\\008-0.404.hdf5\n",
      "Epoch 9/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.4076 - sparse_categorical_accuracy: 0.3885 - val_loss: 1.6029 - val_sparse_categorical_accuracy: 0.2997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.39782\n",
      "Epoch 10/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.3997 - sparse_categorical_accuracy: 0.3942 - val_loss: 1.3836 - val_sparse_categorical_accuracy: 0.4123\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.39782 to 1.38355, saving model to checkpoints\\010-0.412.hdf5\n",
      "Epoch 11/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.3900 - sparse_categorical_accuracy: 0.3934 - val_loss: 1.3803 - val_sparse_categorical_accuracy: 0.4065\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.38355 to 1.38031, saving model to checkpoints\\011-0.406.hdf5\n",
      "Epoch 12/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.3894 - sparse_categorical_accuracy: 0.3956 - val_loss: 1.4845 - val_sparse_categorical_accuracy: 0.3516\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.38031\n",
      "Epoch 13/100\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.3730 - sparse_categorical_accuracy: 0.4040 - val_loss: 1.3719 - val_sparse_categorical_accuracy: 0.4241\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.38031 to 1.37189, saving model to checkpoints\\013-0.424.hdf5\n",
      "Epoch 14/100\n",
      "4082/4082 [==============================] - 25s 6ms/step - loss: 1.3748 - sparse_categorical_accuracy: 0.4094 - val_loss: 1.3615 - val_sparse_categorical_accuracy: 0.4202\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.37189 to 1.36147, saving model to checkpoints\\014-0.420.hdf5\n",
      "Epoch 15/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3568 - sparse_categorical_accuracy: 0.4189 - val_loss: 1.4306 - val_sparse_categorical_accuracy: 0.3928\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.36147\n",
      "Epoch 16/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.3511 - sparse_categorical_accuracy: 0.4297 - val_loss: 1.3481 - val_sparse_categorical_accuracy: 0.4437\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.36147 to 1.34810, saving model to checkpoints\\016-0.444.hdf5\n",
      "Epoch 17/100\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.3493 - sparse_categorical_accuracy: 0.4226 - val_loss: 1.3339 - val_sparse_categorical_accuracy: 0.4525\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.34810 to 1.33386, saving model to checkpoints\\017-0.452.hdf5\n",
      "Epoch 18/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3444 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.4228 - val_sparse_categorical_accuracy: 0.3898\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.33386\n",
      "Epoch 19/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.3424 - sparse_categorical_accuracy: 0.4280 - val_loss: 1.3522 - val_sparse_categorical_accuracy: 0.4035\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.33386\n",
      "Epoch 20/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.3314 - sparse_categorical_accuracy: 0.4314 - val_loss: 1.3386 - val_sparse_categorical_accuracy: 0.4407\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.33386\n",
      "Epoch 21/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3209 - sparse_categorical_accuracy: 0.4415 - val_loss: 1.3644 - val_sparse_categorical_accuracy: 0.4378\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.33386\n",
      "Epoch 22/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3222 - sparse_categorical_accuracy: 0.4471 - val_loss: 1.3329 - val_sparse_categorical_accuracy: 0.4456\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.33386 to 1.33291, saving model to checkpoints\\022-0.446.hdf5\n",
      "Epoch 23/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3123 - sparse_categorical_accuracy: 0.4439 - val_loss: 1.3933 - val_sparse_categorical_accuracy: 0.3898\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.33291\n",
      "Epoch 24/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3137 - sparse_categorical_accuracy: 0.4468 - val_loss: 1.3417 - val_sparse_categorical_accuracy: 0.4574\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.33291\n",
      "Epoch 25/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3095 - sparse_categorical_accuracy: 0.4483 - val_loss: 1.3325 - val_sparse_categorical_accuracy: 0.4456\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.33291 to 1.33252, saving model to checkpoints\\025-0.446.hdf5\n",
      "Epoch 26/100\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.3008 - sparse_categorical_accuracy: 0.4535 - val_loss: 1.3207 - val_sparse_categorical_accuracy: 0.4731\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.33252 to 1.32070, saving model to checkpoints\\026-0.473.hdf5\n",
      "Epoch 27/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2966 - sparse_categorical_accuracy: 0.4525 - val_loss: 1.2976 - val_sparse_categorical_accuracy: 0.4770\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.32070 to 1.29761, saving model to checkpoints\\027-0.477.hdf5\n",
      "Epoch 28/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2952 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.2947 - val_sparse_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.29761 to 1.29466, saving model to checkpoints\\028-0.475.hdf5\n",
      "Epoch 29/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2844 - sparse_categorical_accuracy: 0.4593 - val_loss: 1.3074 - val_sparse_categorical_accuracy: 0.4633\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.29466\n",
      "Epoch 30/100\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2875 - sparse_categorical_accuracy: 0.4701 - val_loss: 1.3314 - val_sparse_categorical_accuracy: 0.4662\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.29466\n",
      "Epoch 31/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2762 - sparse_categorical_accuracy: 0.4576 - val_loss: 1.3485 - val_sparse_categorical_accuracy: 0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss did not improve from 1.29466\n",
      "Epoch 32/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2796 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.3222 - val_sparse_categorical_accuracy: 0.4613\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.29466\n",
      "Epoch 33/100\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2763 - sparse_categorical_accuracy: 0.4782 - val_loss: 1.3136 - val_sparse_categorical_accuracy: 0.4613\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.29466\n"
     ]
    }
   ],
   "source": [
    "########### Stateless LSTM ############\n",
    "x_train, y_train,x_val, y_val = DataSplit(\"x_shuffled_0.npy\", \"y_shuffled_0.npy\")\n",
    "\n",
    "data_dim = x_train.shape[2] #2\n",
    "timesteps = x_train.shape[1] #60\n",
    "nb_classes = len(np.unique(y_train)) #5\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "##################################### Helpers in callbacks ##############################################\n",
    "tb = TensorBoard(log_dir=os.path.join('tensorboard', 'logs',))\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "csv_logger = CSVLogger(os.path.join('logs', str(time.time()) + '.log'))\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join('checkpoints','{epoch:03d}-{val_sparse_categorical_accuracy:.3f}.hdf5'),\n",
    "                                verbose=1,save_best_only=True)\n",
    "history = History()\n",
    "#########################################################################################################\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=64, nb_epoch=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tb, early_stopper, csv_logger, checkpointer, history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_total:  (5103, 60, 2) y_total:  (5103,) x_train length:  (4082, 60, 2) y_train length:  (4082,) x_val length:  (1021, 60, 2) y_val length:  (1021,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue Ma\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4080 samples, validate on 1016 samples\n",
      "Epoch 1/100\n",
      "4080/4080 [==============================] - 40s 10ms/step - loss: 1.5515 - sparse_categorical_accuracy: 0.3015 - val_loss: 1.5401 - val_sparse_categorical_accuracy: 0.2844\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54007, saving model to checkpoints\\001-0.284.hdf5\n",
      "Epoch 2/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.4673 - sparse_categorical_accuracy: 0.3434 - val_loss: 1.4736 - val_sparse_categorical_accuracy: 0.3927\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54007 to 1.47362, saving model to checkpoints\\002-0.393.hdf5\n",
      "Epoch 3/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.4212 - sparse_categorical_accuracy: 0.3718 - val_loss: 1.3848 - val_sparse_categorical_accuracy: 0.4045\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.47362 to 1.38482, saving model to checkpoints\\003-0.405.hdf5\n",
      "Epoch 4/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3957 - sparse_categorical_accuracy: 0.3912 - val_loss: 1.3992 - val_sparse_categorical_accuracy: 0.3927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.38482\n",
      "Epoch 5/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3824 - sparse_categorical_accuracy: 0.4047 - val_loss: 1.3656 - val_sparse_categorical_accuracy: 0.4419\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.38482 to 1.36559, saving model to checkpoints\\005-0.442.hdf5\n",
      "Epoch 6/100\n",
      "4080/4080 [==============================] - 36s 9ms/step - loss: 1.3624 - sparse_categorical_accuracy: 0.4196 - val_loss: 1.3746 - val_sparse_categorical_accuracy: 0.4114\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.36559\n",
      "Epoch 7/100\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 1.3600 - sparse_categorical_accuracy: 0.4199 - val_loss: 1.3471 - val_sparse_categorical_accuracy: 0.4439\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36559 to 1.34706, saving model to checkpoints\\007-0.444.hdf5\n",
      "Epoch 8/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3473 - sparse_categorical_accuracy: 0.4289 - val_loss: 1.3342 - val_sparse_categorical_accuracy: 0.4508\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.34706 to 1.33417, saving model to checkpoints\\008-0.451.hdf5\n",
      "Epoch 9/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3326 - sparse_categorical_accuracy: 0.4360 - val_loss: 1.3324 - val_sparse_categorical_accuracy: 0.4537\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.33417 to 1.33237, saving model to checkpoints\\009-0.454.hdf5\n",
      "Epoch 10/100\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 1.3354 - sparse_categorical_accuracy: 0.4348 - val_loss: 1.3062 - val_sparse_categorical_accuracy: 0.4754\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.33237 to 1.30622, saving model to checkpoints\\010-0.475.hdf5\n",
      "Epoch 11/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3191 - sparse_categorical_accuracy: 0.4429 - val_loss: 1.3207 - val_sparse_categorical_accuracy: 0.4577\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.30622\n",
      "Epoch 12/100\n",
      "4080/4080 [==============================] - 36s 9ms/step - loss: 1.3150 - sparse_categorical_accuracy: 0.4353 - val_loss: 1.3165 - val_sparse_categorical_accuracy: 0.4429\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.30622\n",
      "Epoch 13/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3071 - sparse_categorical_accuracy: 0.4532 - val_loss: 1.3147 - val_sparse_categorical_accuracy: 0.4537\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.30622\n",
      "Epoch 14/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.3039 - sparse_categorical_accuracy: 0.4444 - val_loss: 1.3451 - val_sparse_categorical_accuracy: 0.4616\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.30622\n",
      "Epoch 15/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.2897 - sparse_categorical_accuracy: 0.4588 - val_loss: 1.2935 - val_sparse_categorical_accuracy: 0.4734\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.30622 to 1.29346, saving model to checkpoints\\015-0.473.hdf5\n",
      "Epoch 16/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.2852 - sparse_categorical_accuracy: 0.4586 - val_loss: 1.3084 - val_sparse_categorical_accuracy: 0.4596\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.29346\n",
      "Epoch 17/100\n",
      "4080/4080 [==============================] - 36s 9ms/step - loss: 1.2723 - sparse_categorical_accuracy: 0.4711 - val_loss: 1.3066 - val_sparse_categorical_accuracy: 0.4754\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.29346\n",
      "Epoch 18/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.2664 - sparse_categorical_accuracy: 0.4767 - val_loss: 1.2902 - val_sparse_categorical_accuracy: 0.4843\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.29346 to 1.29023, saving model to checkpoints\\018-0.484.hdf5\n",
      "Epoch 19/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.2544 - sparse_categorical_accuracy: 0.4779 - val_loss: 1.2893 - val_sparse_categorical_accuracy: 0.4685\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.29023 to 1.28935, saving model to checkpoints\\019-0.469.hdf5\n",
      "Epoch 20/100\n",
      "4080/4080 [==============================] - 55s 13ms/step - loss: 1.2556 - sparse_categorical_accuracy: 0.4784 - val_loss: 1.2667 - val_sparse_categorical_accuracy: 0.4951\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.28935 to 1.26671, saving model to checkpoints\\020-0.495.hdf5\n",
      "Epoch 21/100\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 1.2373 - sparse_categorical_accuracy: 0.4953 - val_loss: 1.2657 - val_sparse_categorical_accuracy: 0.4941\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.26671 to 1.26569, saving model to checkpoints\\021-0.494.hdf5\n",
      "Epoch 22/100\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 1.2393 - sparse_categorical_accuracy: 0.4914 - val_loss: 1.2862 - val_sparse_categorical_accuracy: 0.4783\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.26569\n",
      "Epoch 23/100\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 1.2159 - sparse_categorical_accuracy: 0.5071 - val_loss: 1.2639 - val_sparse_categorical_accuracy: 0.5039\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.26569 to 1.26387, saving model to checkpoints\\023-0.504.hdf5\n",
      "Epoch 24/100\n",
      "4080/4080 [==============================] - 42s 10ms/step - loss: 1.2045 - sparse_categorical_accuracy: 0.5032 - val_loss: 1.2664 - val_sparse_categorical_accuracy: 0.4793\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.26387\n",
      "Epoch 25/100\n",
      "4080/4080 [==============================] - 46s 11ms/step - loss: 1.2024 - sparse_categorical_accuracy: 0.5098 - val_loss: 1.2672 - val_sparse_categorical_accuracy: 0.4774\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.26387\n",
      "Epoch 26/100\n",
      "4080/4080 [==============================] - 45s 11ms/step - loss: 1.1916 - sparse_categorical_accuracy: 0.5196 - val_loss: 1.2557 - val_sparse_categorical_accuracy: 0.4843\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.26387 to 1.25567, saving model to checkpoints\\026-0.484.hdf5\n",
      "Epoch 27/100\n",
      "4080/4080 [==============================] - 42s 10ms/step - loss: 1.1902 - sparse_categorical_accuracy: 0.5174 - val_loss: 1.2375 - val_sparse_categorical_accuracy: 0.5049\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.25567 to 1.23752, saving model to checkpoints\\027-0.505.hdf5\n",
      "Epoch 28/100\n",
      "4080/4080 [==============================] - 43s 10ms/step - loss: 1.1816 - sparse_categorical_accuracy: 0.5169 - val_loss: 1.2473 - val_sparse_categorical_accuracy: 0.4862\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.23752\n",
      "Epoch 29/100\n",
      "4080/4080 [==============================] - 43s 10ms/step - loss: 1.1751 - sparse_categorical_accuracy: 0.5199 - val_loss: 1.2158 - val_sparse_categorical_accuracy: 0.5344\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.23752 to 1.21579, saving model to checkpoints\\029-0.534.hdf5\n",
      "Epoch 30/100\n",
      "4080/4080 [==============================] - 42s 10ms/step - loss: 1.1641 - sparse_categorical_accuracy: 0.5252 - val_loss: 1.2542 - val_sparse_categorical_accuracy: 0.4911\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.21579\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4080/4080 [==============================] - 41s 10ms/step - loss: 1.1448 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.2526 - val_sparse_categorical_accuracy: 0.4852 - spars\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.21579\n",
      "Epoch 32/100\n",
      "4080/4080 [==============================] - 47s 12ms/step - loss: 1.1442 - sparse_categorical_accuracy: 0.5355 - val_loss: 1.2399 - val_sparse_categorical_accuracy: 0.5039\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.21579\n",
      "Epoch 33/100\n",
      "4080/4080 [==============================] - 40s 10ms/step - loss: 1.1379 - sparse_categorical_accuracy: 0.5395 - val_loss: 1.2605 - val_sparse_categorical_accuracy: 0.4813\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.21579\n",
      "Epoch 34/100\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 1.1264 - sparse_categorical_accuracy: 0.5453 - val_loss: 1.2443 - val_sparse_categorical_accuracy: 0.5030\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.21579\n"
     ]
    }
   ],
   "source": [
    "########### Stateful LSTM ############\n",
    "x_train, y_train,x_val, y_val = DataSplit(\"x_shuffled_0.npy\", \"y_shuffled_0.npy\")\n",
    "x_train = x_train[:4080]\n",
    "y_train = y_train[:4080]\n",
    "x_val = x_val[:1016]\n",
    "y_val = y_val[:1016]\n",
    "\n",
    "data_dim = x_train.shape[2] #2\n",
    "timesteps = x_train.shape[1] #60\n",
    "nb_classes = len(np.unique(y_train)) #5\n",
    "batch_size = 8\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "##################################### Helpers in callbacks ##############################################\n",
    "tb = TensorBoard(log_dir=os.path.join('tensorboard', 'logs',))\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "csv_logger = CSVLogger(os.path.join('logs', str(time.time()) + '.log'))\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join('checkpoints','{epoch:03d}-{val_sparse_categorical_accuracy:.3f}.hdf5'),\n",
    "                                verbose=1,save_best_only=True)\n",
    "history = History()\n",
    "#########################################################################################################\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, nb_epoch=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tb, early_stopper, csv_logger, checkpointer, history])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_a.shape (4082, 60, 1)\n",
      "x_val_a.shape (4082, 60, 1)\n",
      "y_val_a.shape (4082,)\n"
     ]
    }
   ],
   "source": [
    "def DataTwoStream(x_total_addr, y_total_addr, val_ratio = 0.2):\n",
    "    x_total = np.load(x_total_addr)\n",
    "    y_total = np.load(y_total_addr)\n",
    "    index_split = int(x_total.shape[0]*0.8)\n",
    "    x_train_a = x_total[:index_split,:,0]\n",
    "    x_train_a = x_train_a.reshape((x_train_a.shape[0],x_train_a.shape[1],1))\n",
    "    x_train_b = x_total[:index_split,:,1]\n",
    "    x_train_b =x_train_b.reshape((x_train_a.shape[0],x_train_a.shape[1],1))\n",
    "    y_train = y_total[:index_split]\n",
    "    x_val_a = x_total[:index_split,:,0]\n",
    "    x_val_a = x_val_a.reshape((x_val_a.shape[0],x_val_a.shape[1],1))\n",
    "    x_val_b = x_total[:index_split,:,1]\n",
    "    x_val_b = x_val_b.reshape((x_val_a.shape[0],x_val_a.shape[1],1))\n",
    "    y_val = y_total[:index_split]\n",
    "    return x_train_a, x_train_b, y_train, x_val_a, x_val_b, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4082 samples, validate on 4082 samples\n",
      "Epoch 1/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.5471 - sparse_categorical_accuracy: 0.3099 - val_loss: 1.4738 - val_sparse_categorical_accuracy: 0.3503\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.47383, saving model to checkpoints\\001-0.350.hdf5\n",
      "Epoch 2/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 1.4698 - sparse_categorical_accuracy: 0.3496 - val_loss: 1.4651 - val_sparse_categorical_accuracy: 0.3361\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.47383 to 1.46508, saving model to checkpoints\\002-0.336.hdf5\n",
      "Epoch 3/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 1.4591 - sparse_categorical_accuracy: 0.3596 - val_loss: 1.4428 - val_sparse_categorical_accuracy: 0.3704\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46508 to 1.44279, saving model to checkpoints\\003-0.370.hdf5\n",
      "Epoch 4/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.4496 - sparse_categorical_accuracy: 0.3579 - val_loss: 1.4262 - val_sparse_categorical_accuracy: 0.3760\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.44279 to 1.42619, saving model to checkpoints\\004-0.376.hdf5\n",
      "Epoch 5/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.4371 - sparse_categorical_accuracy: 0.3677 - val_loss: 1.4519 - val_sparse_categorical_accuracy: 0.3530\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.42619\n",
      "Epoch 6/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4191 - sparse_categorical_accuracy: 0.3731 - val_loss: 1.3918 - val_sparse_categorical_accuracy: 0.3829\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42619 to 1.39176, saving model to checkpoints\\006-0.383.hdf5\n",
      "Epoch 7/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4137 - sparse_categorical_accuracy: 0.3829 - val_loss: 1.3878 - val_sparse_categorical_accuracy: 0.3942\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.39176 to 1.38777, saving model to checkpoints\\007-0.394.hdf5\n",
      "Epoch 8/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.4086 - sparse_categorical_accuracy: 0.3795 - val_loss: 1.4298 - val_sparse_categorical_accuracy: 0.3442\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.38777\n",
      "Epoch 9/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3909 - sparse_categorical_accuracy: 0.3880 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.38777 to 1.35993, saving model to checkpoints\\009-0.406.hdf5\n",
      "Epoch 10/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3841 - sparse_categorical_accuracy: 0.3922 - val_loss: 1.3565 - val_sparse_categorical_accuracy: 0.4101\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.35993 to 1.35648, saving model to checkpoints\\010-0.410.hdf5\n",
      "Epoch 11/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3789 - sparse_categorical_accuracy: 0.3934 - val_loss: 1.3455 - val_sparse_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.35648 to 1.34550, saving model to checkpoints\\011-0.423.hdf5\n",
      "Epoch 12/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3682 - sparse_categorical_accuracy: 0.4064 - val_loss: 1.3412 - val_sparse_categorical_accuracy: 0.4089\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.34550 to 1.34117, saving model to checkpoints\\012-0.409.hdf5\n",
      "Epoch 13/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3600 - sparse_categorical_accuracy: 0.4072 - val_loss: 1.3390 - val_sparse_categorical_accuracy: 0.4233\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.34117 to 1.33897, saving model to checkpoints\\013-0.423.hdf5\n",
      "Epoch 14/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3565 - sparse_categorical_accuracy: 0.4067 - val_loss: 1.3849 - val_sparse_categorical_accuracy: 0.4086\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.33897\n",
      "Epoch 15/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3428 - sparse_categorical_accuracy: 0.4233 - val_loss: 1.3445 - val_sparse_categorical_accuracy: 0.4209\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.33897\n",
      "Epoch 16/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3457 - sparse_categorical_accuracy: 0.4233 - val_loss: 1.3077 - val_sparse_categorical_accuracy: 0.4370\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.33897 to 1.30773, saving model to checkpoints\\016-0.437.hdf5\n",
      "Epoch 17/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3378 - sparse_categorical_accuracy: 0.4236 - val_loss: 1.3776 - val_sparse_categorical_accuracy: 0.3895\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.30773\n",
      "Epoch 18/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3346 - sparse_categorical_accuracy: 0.4221 - val_loss: 1.3005 - val_sparse_categorical_accuracy: 0.4397\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.30773 to 1.30050, saving model to checkpoints\\018-0.440.hdf5\n",
      "Epoch 19/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3276 - sparse_categorical_accuracy: 0.4321 - val_loss: 1.3021 - val_sparse_categorical_accuracy: 0.4424\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.30050\n",
      "Epoch 20/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3198 - sparse_categorical_accuracy: 0.4334 - val_loss: 1.3047 - val_sparse_categorical_accuracy: 0.4429\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.30050\n",
      "Epoch 21/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3166 - sparse_categorical_accuracy: 0.4397 - val_loss: 1.3126 - val_sparse_categorical_accuracy: 0.4417\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.30050\n",
      "Epoch 22/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3120 - sparse_categorical_accuracy: 0.4410 - val_loss: 1.2926 - val_sparse_categorical_accuracy: 0.4444\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.30050 to 1.29263, saving model to checkpoints\\022-0.444.hdf5\n",
      "Epoch 23/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.3089 - sparse_categorical_accuracy: 0.4397 - val_loss: 1.2811 - val_sparse_categorical_accuracy: 0.4591\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.29263 to 1.28109, saving model to checkpoints\\023-0.459.hdf5\n",
      "Epoch 24/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2971 - sparse_categorical_accuracy: 0.4515 - val_loss: 1.2750 - val_sparse_categorical_accuracy: 0.4586\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.28109 to 1.27496, saving model to checkpoints\\024-0.459.hdf5\n",
      "Epoch 25/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2934 - sparse_categorical_accuracy: 0.4424 - val_loss: 1.2666 - val_sparse_categorical_accuracy: 0.4657\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.27496 to 1.26656, saving model to checkpoints\\025-0.466.hdf5\n",
      "Epoch 26/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2931 - sparse_categorical_accuracy: 0.4554 - val_loss: 1.2696 - val_sparse_categorical_accuracy: 0.4635\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.26656\n",
      "Epoch 27/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2885 - sparse_categorical_accuracy: 0.4532 - val_loss: 1.2696 - val_sparse_categorical_accuracy: 0.4625\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.26656\n",
      "Epoch 28/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2804 - sparse_categorical_accuracy: 0.4574 - val_loss: 1.2558 - val_sparse_categorical_accuracy: 0.4748\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.26656 to 1.25577, saving model to checkpoints\\028-0.475.hdf5\n",
      "Epoch 29/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2798 - sparse_categorical_accuracy: 0.4588 - val_loss: 1.2445 - val_sparse_categorical_accuracy: 0.4760\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.25577 to 1.24447, saving model to checkpoints\\029-0.476.hdf5\n",
      "Epoch 30/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 1.2743 - sparse_categorical_accuracy: 0.4613 - val_loss: 1.2422 - val_sparse_categorical_accuracy: 0.4728\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.24447 to 1.24221, saving model to checkpoints\\030-0.473.hdf5\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 17s 4ms/step - loss: 1.2696 - sparse_categorical_accuracy: 0.4669 - val_loss: 1.2325 - val_sparse_categorical_accuracy: 0.4804\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.24221 to 1.23248, saving model to checkpoints\\031-0.480.hdf5\n",
      "Epoch 32/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 1.2642 - sparse_categorical_accuracy: 0.4711 - val_loss: 1.2435 - val_sparse_categorical_accuracy: 0.4777\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.23248\n",
      "Epoch 33/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.2600 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.2380 - val_sparse_categorical_accuracy: 0.4731\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.23248\n",
      "Epoch 34/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.2609 - sparse_categorical_accuracy: 0.4633 - val_loss: 1.2378 - val_sparse_categorical_accuracy: 0.4767\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.23248\n",
      "Epoch 35/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 1.2548 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.2284 - val_sparse_categorical_accuracy: 0.4811\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.23248 to 1.22843, saving model to checkpoints\\035-0.481.hdf5\n",
      "Epoch 36/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.2592 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.2214 - val_sparse_categorical_accuracy: 0.4875\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.22843 to 1.22144, saving model to checkpoints\\036-0.488.hdf5\n",
      "Epoch 37/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2544 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.2503 - val_sparse_categorical_accuracy: 0.4659\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.22144\n",
      "Epoch 38/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2442 - sparse_categorical_accuracy: 0.4731 - val_loss: 1.2638 - val_sparse_categorical_accuracy: 0.4603\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.22144\n",
      "Epoch 39/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2453 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.2102 - val_sparse_categorical_accuracy: 0.4963\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.22144 to 1.21016, saving model to checkpoints\\039-0.496.hdf5\n",
      "Epoch 40/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2398 - sparse_categorical_accuracy: 0.4821 - val_loss: 1.2202 - val_sparse_categorical_accuracy: 0.4875\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.21016\n",
      "Epoch 41/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2398 - sparse_categorical_accuracy: 0.4831 - val_loss: 1.2229 - val_sparse_categorical_accuracy: 0.4865\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.21016\n",
      "Epoch 42/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2321 - sparse_categorical_accuracy: 0.4824 - val_loss: 1.2014 - val_sparse_categorical_accuracy: 0.5017\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.21016 to 1.20137, saving model to checkpoints\\042-0.502.hdf5\n",
      "Epoch 43/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2297 - sparse_categorical_accuracy: 0.4863 - val_loss: 1.2040 - val_sparse_categorical_accuracy: 0.5078\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.20137\n",
      "Epoch 44/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2271 - sparse_categorical_accuracy: 0.4870 - val_loss: 1.1859 - val_sparse_categorical_accuracy: 0.5078\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.20137 to 1.18588, saving model to checkpoints\\044-0.508.hdf5\n",
      "Epoch 45/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2252 - sparse_categorical_accuracy: 0.4865 - val_loss: 1.1803 - val_sparse_categorical_accuracy: 0.5130\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.18588 to 1.18034, saving model to checkpoints\\045-0.513.hdf5\n",
      "Epoch 46/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2127 - sparse_categorical_accuracy: 0.4953 - val_loss: 1.2381 - val_sparse_categorical_accuracy: 0.4819\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.18034\n",
      "Epoch 47/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2110 - sparse_categorical_accuracy: 0.4958 - val_loss: 1.2309 - val_sparse_categorical_accuracy: 0.4777\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.18034\n",
      "Epoch 48/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2068 - sparse_categorical_accuracy: 0.5012 - val_loss: 1.1764 - val_sparse_categorical_accuracy: 0.5162\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.18034 to 1.17640, saving model to checkpoints\\048-0.516.hdf5\n",
      "Epoch 49/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2124 - sparse_categorical_accuracy: 0.4936 - val_loss: 1.1787 - val_sparse_categorical_accuracy: 0.5145\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.17640\n",
      "Epoch 50/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2078 - sparse_categorical_accuracy: 0.5010 - val_loss: 1.1703 - val_sparse_categorical_accuracy: 0.5243\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.17640 to 1.17031, saving model to checkpoints\\050-0.524.hdf5\n",
      "Epoch 51/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.2012 - sparse_categorical_accuracy: 0.5034 - val_loss: 1.1771 - val_sparse_categorical_accuracy: 0.5171\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.17031\n",
      "Epoch 52/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1919 - sparse_categorical_accuracy: 0.5024 - val_loss: 1.1785 - val_sparse_categorical_accuracy: 0.5152\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.17031\n",
      "Epoch 53/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.1945 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.1419 - val_sparse_categorical_accuracy: 0.5336\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.17031 to 1.14189, saving model to checkpoints\\053-0.534.hdf5\n",
      "Epoch 54/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1878 - sparse_categorical_accuracy: 0.5039 - val_loss: 1.2393 - val_sparse_categorical_accuracy: 0.4628\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.14189\n",
      "Epoch 55/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 1.1961 - sparse_categorical_accuracy: 0.5020 - val_loss: 1.1543 - val_sparse_categorical_accuracy: 0.5257\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.14189\n",
      "Epoch 56/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.1864 - sparse_categorical_accuracy: 0.5032 - val_loss: 1.1727 - val_sparse_categorical_accuracy: 0.5179\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.14189\n",
      "Epoch 57/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 1.1864 - sparse_categorical_accuracy: 0.5017 - val_loss: 1.1552 - val_sparse_categorical_accuracy: 0.5260\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.14189\n",
      "Epoch 58/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 1.1790 - sparse_categorical_accuracy: 0.5181 - val_loss: 1.1362 - val_sparse_categorical_accuracy: 0.5328\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.14189 to 1.13615, saving model to checkpoints\\058-0.533.hdf5\n",
      "Epoch 59/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1800 - sparse_categorical_accuracy: 0.5066 - val_loss: 1.1308 - val_sparse_categorical_accuracy: 0.5360\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.13615 to 1.13081, saving model to checkpoints\\059-0.536.hdf5\n",
      "Epoch 60/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1778 - sparse_categorical_accuracy: 0.5098 - val_loss: 1.1832 - val_sparse_categorical_accuracy: 0.5169\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.13081\n",
      "Epoch 61/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 1.1735 - sparse_categorical_accuracy: 0.5091 - val_loss: 1.1286 - val_sparse_categorical_accuracy: 0.5392\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.13081 to 1.12858, saving model to checkpoints\\061-0.539.hdf5\n",
      "Epoch 62/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 1.1726 - sparse_categorical_accuracy: 0.5157 - val_loss: 1.1293 - val_sparse_categorical_accuracy: 0.5360\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.12858\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1585 - sparse_categorical_accuracy: 0.5125 - val_loss: 1.1165 - val_sparse_categorical_accuracy: 0.5345\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.12858 to 1.11652, saving model to checkpoints\\063-0.535.hdf5\n",
      "Epoch 64/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1663 - sparse_categorical_accuracy: 0.5167 - val_loss: 1.1341 - val_sparse_categorical_accuracy: 0.5360\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.11652\n",
      "Epoch 65/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1578 - sparse_categorical_accuracy: 0.5162 - val_loss: 1.1149 - val_sparse_categorical_accuracy: 0.5424\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.11652 to 1.11486, saving model to checkpoints\\065-0.542.hdf5\n",
      "Epoch 66/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1530 - sparse_categorical_accuracy: 0.5184 - val_loss: 1.1054 - val_sparse_categorical_accuracy: 0.5473\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.11486 to 1.10538, saving model to checkpoints\\066-0.547.hdf5\n",
      "Epoch 67/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1500 - sparse_categorical_accuracy: 0.5235 - val_loss: 1.1216 - val_sparse_categorical_accuracy: 0.5412\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.10538\n",
      "Epoch 68/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1425 - sparse_categorical_accuracy: 0.5311 - val_loss: 1.1033 - val_sparse_categorical_accuracy: 0.5480\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.10538 to 1.10326, saving model to checkpoints\\068-0.548.hdf5\n",
      "Epoch 69/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1459 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.1391 - val_sparse_categorical_accuracy: 0.5314\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.10326\n",
      "Epoch 70/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1464 - sparse_categorical_accuracy: 0.5328 - val_loss: 1.0866 - val_sparse_categorical_accuracy: 0.5554\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.10326 to 1.08656, saving model to checkpoints\\070-0.555.hdf5\n",
      "Epoch 71/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1370 - sparse_categorical_accuracy: 0.5262 - val_loss: 1.0994 - val_sparse_categorical_accuracy: 0.5443\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.08656\n",
      "Epoch 72/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1434 - sparse_categorical_accuracy: 0.5196 - val_loss: 1.0868 - val_sparse_categorical_accuracy: 0.5610\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.08656\n",
      "Epoch 73/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1360 - sparse_categorical_accuracy: 0.5282 - val_loss: 1.1098 - val_sparse_categorical_accuracy: 0.5392\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.08656\n",
      "Epoch 74/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1256 - sparse_categorical_accuracy: 0.5404 - val_loss: 1.0774 - val_sparse_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.08656 to 1.07744, saving model to checkpoints\\074-0.562.hdf5\n",
      "Epoch 75/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1366 - sparse_categorical_accuracy: 0.5304 - val_loss: 1.0943 - val_sparse_categorical_accuracy: 0.5448\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.07744\n",
      "Epoch 76/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 1.1245 - sparse_categorical_accuracy: 0.5385 - val_loss: 1.0773 - val_sparse_categorical_accuracy: 0.5541\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.07744 to 1.07732, saving model to checkpoints\\076-0.554.hdf5\n",
      "Epoch 77/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1259 - sparse_categorical_accuracy: 0.5333 - val_loss: 1.0925 - val_sparse_categorical_accuracy: 0.5488\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.07732\n",
      "Epoch 78/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1164 - sparse_categorical_accuracy: 0.5355 - val_loss: 1.0689 - val_sparse_categorical_accuracy: 0.5644\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.07732 to 1.06888, saving model to checkpoints\\078-0.564.hdf5\n",
      "Epoch 79/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1200 - sparse_categorical_accuracy: 0.5488 - val_loss: 1.0550 - val_sparse_categorical_accuracy: 0.5627\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.06888 to 1.05504, saving model to checkpoints\\079-0.563.hdf5\n",
      "Epoch 80/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1062 - sparse_categorical_accuracy: 0.5488 - val_loss: 1.0541 - val_sparse_categorical_accuracy: 0.5747\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.05504 to 1.05412, saving model to checkpoints\\080-0.575.hdf5\n",
      "Epoch 81/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.1068 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.1204 - val_sparse_categorical_accuracy: 0.5145\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.05412\n",
      "Epoch 82/500\n",
      "4082/4082 [==============================] - 18s 5ms/step - loss: 1.1097 - sparse_categorical_accuracy: 0.5448 - val_loss: 1.0674 - val_sparse_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.05412\n",
      "Epoch 83/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 1.1043 - sparse_categorical_accuracy: 0.5412 - val_loss: 1.0428 - val_sparse_categorical_accuracy: 0.5720\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.05412 to 1.04279, saving model to checkpoints\\083-0.572.hdf5\n",
      "Epoch 84/500\n",
      "4082/4082 [==============================] - 28s 7ms/step - loss: 1.1038 - sparse_categorical_accuracy: 0.5429 - val_loss: 1.0574 - val_sparse_categorical_accuracy: 0.5674\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.04279\n",
      "Epoch 85/500\n",
      "4082/4082 [==============================] - 32s 8ms/step - loss: 1.1002 - sparse_categorical_accuracy: 0.5385 - val_loss: 1.0351 - val_sparse_categorical_accuracy: 0.5745\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.04279 to 1.03509, saving model to checkpoints\\085-0.574.hdf5\n",
      "Epoch 86/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.1009 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.0726 - val_sparse_categorical_accuracy: 0.5612\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.03509\n",
      "Epoch 87/500\n",
      "4082/4082 [==============================] - 30s 7ms/step - loss: 1.0885 - sparse_categorical_accuracy: 0.5537 - val_loss: 1.0208 - val_sparse_categorical_accuracy: 0.5848\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.03509 to 1.02078, saving model to checkpoints\\087-0.585.hdf5\n",
      "Epoch 88/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.0885 - sparse_categorical_accuracy: 0.5512 - val_loss: 1.0336 - val_sparse_categorical_accuracy: 0.5821\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.02078\n",
      "Epoch 89/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.0785 - sparse_categorical_accuracy: 0.5510 - val_loss: 1.0261 - val_sparse_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.02078\n",
      "Epoch 90/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.0862 - sparse_categorical_accuracy: 0.5507 - val_loss: 1.0391 - val_sparse_categorical_accuracy: 0.5745\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.02078\n",
      "Epoch 91/500\n",
      "4082/4082 [==============================] - 30s 7ms/step - loss: 1.0766 - sparse_categorical_accuracy: 0.5549 - val_loss: 1.0208 - val_sparse_categorical_accuracy: 0.5838\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.02078\n",
      "Epoch 92/500\n",
      "4082/4082 [==============================] - 29s 7ms/step - loss: 1.0822 - sparse_categorical_accuracy: 0.5505 - val_loss: 1.0158 - val_sparse_categorical_accuracy: 0.5784\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.02078 to 1.01576, saving model to checkpoints\\092-0.578.hdf5\n",
      "Epoch 93/500\n",
      "4082/4082 [==============================] - 35s 8ms/step - loss: 1.0705 - sparse_categorical_accuracy: 0.5642 - val_loss: 1.0190 - val_sparse_categorical_accuracy: 0.5818\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.01576\n",
      "Epoch 94/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 1.0744 - sparse_categorical_accuracy: 0.5639 - val_loss: 1.0445 - val_sparse_categorical_accuracy: 0.5713\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.01576\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0699 - sparse_categorical_accuracy: 0.5652 - val_loss: 1.0219 - val_sparse_categorical_accuracy: 0.5813\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.01576\n",
      "Epoch 96/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0595 - sparse_categorical_accuracy: 0.5605 - val_loss: 1.0306 - val_sparse_categorical_accuracy: 0.5823\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.01576\n",
      "Epoch 97/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0563 - sparse_categorical_accuracy: 0.5664 - val_loss: 0.9981 - val_sparse_categorical_accuracy: 0.5977\n",
      "\n",
      "Epoch 00097: val_loss improved from 1.01576 to 0.99809, saving model to checkpoints\\097-0.598.hdf5\n",
      "Epoch 98/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0650 - sparse_categorical_accuracy: 0.5512 - val_loss: 0.9883 - val_sparse_categorical_accuracy: 0.5975\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.99809 to 0.98831, saving model to checkpoints\\098-0.598.hdf5\n",
      "Epoch 99/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0559 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.9933 - val_sparse_categorical_accuracy: 0.5960\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.98831\n",
      "Epoch 100/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0590 - sparse_categorical_accuracy: 0.5634 - val_loss: 0.9801 - val_sparse_categorical_accuracy: 0.6056\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.98831 to 0.98014, saving model to checkpoints\\100-0.606.hdf5\n",
      "Epoch 101/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 1.0429 - sparse_categorical_accuracy: 0.5654 - val_loss: 0.9756 - val_sparse_categorical_accuracy: 0.6078\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.98014 to 0.97556, saving model to checkpoints\\101-0.608.hdf5\n",
      "Epoch 102/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 1.0462 - sparse_categorical_accuracy: 0.5634 - val_loss: 0.9782 - val_sparse_categorical_accuracy: 0.6034\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.97556\n",
      "Epoch 103/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0489 - sparse_categorical_accuracy: 0.5696 - val_loss: 0.9796 - val_sparse_categorical_accuracy: 0.5968\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.97556\n",
      "Epoch 104/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0408 - sparse_categorical_accuracy: 0.5681 - val_loss: 0.9735 - val_sparse_categorical_accuracy: 0.6127\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.97556 to 0.97352, saving model to checkpoints\\104-0.613.hdf5\n",
      "Epoch 105/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0401 - sparse_categorical_accuracy: 0.5718 - val_loss: 0.9579 - val_sparse_categorical_accuracy: 0.6110\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.97352 to 0.95795, saving model to checkpoints\\105-0.611.hdf5\n",
      "Epoch 106/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0407 - sparse_categorical_accuracy: 0.5742 - val_loss: 0.9751 - val_sparse_categorical_accuracy: 0.6083\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.95795\n",
      "Epoch 107/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0432 - sparse_categorical_accuracy: 0.5745 - val_loss: 0.9712 - val_sparse_categorical_accuracy: 0.6049\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.95795\n",
      "Epoch 108/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0220 - sparse_categorical_accuracy: 0.5769 - val_loss: 0.9539 - val_sparse_categorical_accuracy: 0.6127\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.95795 to 0.95393, saving model to checkpoints\\108-0.613.hdf5\n",
      "Epoch 109/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0347 - sparse_categorical_accuracy: 0.5713 - val_loss: 0.9600 - val_sparse_categorical_accuracy: 0.6159\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.95393\n",
      "Epoch 110/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0337 - sparse_categorical_accuracy: 0.5730 - val_loss: 0.9652 - val_sparse_categorical_accuracy: 0.6063\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.95393\n",
      "Epoch 111/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0248 - sparse_categorical_accuracy: 0.5681 - val_loss: 0.9782 - val_sparse_categorical_accuracy: 0.5943\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.95393\n",
      "Epoch 112/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0219 - sparse_categorical_accuracy: 0.5808 - val_loss: 0.9575 - val_sparse_categorical_accuracy: 0.6115\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.95393\n",
      "Epoch 113/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0167 - sparse_categorical_accuracy: 0.5816 - val_loss: 0.9683 - val_sparse_categorical_accuracy: 0.6090\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.95393\n",
      "Epoch 114/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0185 - sparse_categorical_accuracy: 0.5747 - val_loss: 0.9486 - val_sparse_categorical_accuracy: 0.6134\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.95393 to 0.94864, saving model to checkpoints\\114-0.613.hdf5\n",
      "Epoch 115/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0131 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.9247 - val_sparse_categorical_accuracy: 0.6281\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.94864 to 0.92472, saving model to checkpoints\\115-0.628.hdf5\n",
      "Epoch 116/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0054 - sparse_categorical_accuracy: 0.5909 - val_loss: 0.9613 - val_sparse_categorical_accuracy: 0.6041\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.92472\n",
      "Epoch 117/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0175 - sparse_categorical_accuracy: 0.5728 - val_loss: 0.9584 - val_sparse_categorical_accuracy: 0.6112\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.92472\n",
      "Epoch 118/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9967 - sparse_categorical_accuracy: 0.5936 - val_loss: 0.9435 - val_sparse_categorical_accuracy: 0.6218\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.92472\n",
      "Epoch 119/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0004 - sparse_categorical_accuracy: 0.5845 - val_loss: 0.9254 - val_sparse_categorical_accuracy: 0.6298\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.92472\n",
      "Epoch 120/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9876 - sparse_categorical_accuracy: 0.5953 - val_loss: 0.9680 - val_sparse_categorical_accuracy: 0.6080\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.92472\n",
      "Epoch 121/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9955 - sparse_categorical_accuracy: 0.5808 - val_loss: 0.9545 - val_sparse_categorical_accuracy: 0.6129\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.92472\n",
      "Epoch 122/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 1.0050 - sparse_categorical_accuracy: 0.5855 - val_loss: 0.9112 - val_sparse_categorical_accuracy: 0.6267\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.92472 to 0.91123, saving model to checkpoints\\122-0.627.hdf5\n",
      "Epoch 123/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9910 - sparse_categorical_accuracy: 0.5953 - val_loss: 0.8940 - val_sparse_categorical_accuracy: 0.6411\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.91123 to 0.89397, saving model to checkpoints\\123-0.641.hdf5\n",
      "Epoch 124/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.9909 - sparse_categorical_accuracy: 0.5985 - val_loss: 0.9076 - val_sparse_categorical_accuracy: 0.6369\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.89397\n",
      "Epoch 125/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9843 - sparse_categorical_accuracy: 0.5941 - val_loss: 0.9054 - val_sparse_categorical_accuracy: 0.6387\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.89397\n",
      "Epoch 126/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9824 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.6338\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.89397\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9762 - sparse_categorical_accuracy: 0.5955 - val_loss: 0.9124 - val_sparse_categorical_accuracy: 0.6325\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.89397\n",
      "Epoch 128/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9746 - sparse_categorical_accuracy: 0.6022 - val_loss: 0.9078 - val_sparse_categorical_accuracy: 0.6286\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.89397\n",
      "Epoch 129/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9770 - sparse_categorical_accuracy: 0.5977 - val_loss: 0.9197 - val_sparse_categorical_accuracy: 0.6230\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.89397\n",
      "Epoch 130/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9797 - sparse_categorical_accuracy: 0.5980 - val_loss: 0.8995 - val_sparse_categorical_accuracy: 0.6330\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.89397\n",
      "Epoch 131/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9720 - sparse_categorical_accuracy: 0.6019 - val_loss: 0.8774 - val_sparse_categorical_accuracy: 0.6516\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.89397 to 0.87744, saving model to checkpoints\\131-0.652.hdf5\n",
      "Epoch 132/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9673 - sparse_categorical_accuracy: 0.6068 - val_loss: 0.8671 - val_sparse_categorical_accuracy: 0.6592\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.87744 to 0.86706, saving model to checkpoints\\132-0.659.hdf5\n",
      "Epoch 133/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9671 - sparse_categorical_accuracy: 0.6034 - val_loss: 0.8997 - val_sparse_categorical_accuracy: 0.6357\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.86706\n",
      "Epoch 134/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9692 - sparse_categorical_accuracy: 0.6036 - val_loss: 0.8701 - val_sparse_categorical_accuracy: 0.6568\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.86706\n",
      "Epoch 135/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9560 - sparse_categorical_accuracy: 0.6110 - val_loss: 0.8846 - val_sparse_categorical_accuracy: 0.6492\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.86706\n",
      "Epoch 136/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9606 - sparse_categorical_accuracy: 0.6093 - val_loss: 0.8557 - val_sparse_categorical_accuracy: 0.6661\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.86706 to 0.85566, saving model to checkpoints\\136-0.666.hdf5\n",
      "Epoch 137/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9543 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.8647 - val_sparse_categorical_accuracy: 0.6531\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.85566\n",
      "Epoch 138/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9579 - sparse_categorical_accuracy: 0.6151 - val_loss: 0.8860 - val_sparse_categorical_accuracy: 0.6480\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.85566\n",
      "Epoch 139/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9554 - sparse_categorical_accuracy: 0.6146 - val_loss: 0.9117 - val_sparse_categorical_accuracy: 0.6291\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.85566\n",
      "Epoch 140/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9474 - sparse_categorical_accuracy: 0.6007 - val_loss: 0.8618 - val_sparse_categorical_accuracy: 0.6534\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.85566\n",
      "Epoch 141/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9522 - sparse_categorical_accuracy: 0.6063 - val_loss: 0.8439 - val_sparse_categorical_accuracy: 0.6712\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.85566 to 0.84388, saving model to checkpoints\\141-0.671.hdf5\n",
      "Epoch 142/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9446 - sparse_categorical_accuracy: 0.6066 - val_loss: 0.9534 - val_sparse_categorical_accuracy: 0.6134\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.84388\n",
      "Epoch 143/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9367 - sparse_categorical_accuracy: 0.6151 - val_loss: 0.8578 - val_sparse_categorical_accuracy: 0.6585\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.84388\n",
      "Epoch 144/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9430 - sparse_categorical_accuracy: 0.6181 - val_loss: 0.8677 - val_sparse_categorical_accuracy: 0.6568\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.84388\n",
      "Epoch 145/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9398 - sparse_categorical_accuracy: 0.6115 - val_loss: 0.8486 - val_sparse_categorical_accuracy: 0.6639\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.84388\n",
      "Epoch 146/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9335 - sparse_categorical_accuracy: 0.6178 - val_loss: 0.8353 - val_sparse_categorical_accuracy: 0.6663\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.84388 to 0.83531, saving model to checkpoints\\146-0.666.hdf5\n",
      "Epoch 147/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.9320 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.8802 - val_sparse_categorical_accuracy: 0.6482\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.83531\n",
      "Epoch 148/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9354 - sparse_categorical_accuracy: 0.6159 - val_loss: 0.8183 - val_sparse_categorical_accuracy: 0.6813\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.83531 to 0.81832, saving model to checkpoints\\148-0.681.hdf5\n",
      "Epoch 149/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9284 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.8518 - val_sparse_categorical_accuracy: 0.6612\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.81832\n",
      "Epoch 150/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9367 - sparse_categorical_accuracy: 0.6151 - val_loss: 0.8503 - val_sparse_categorical_accuracy: 0.6583\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.81832\n",
      "Epoch 151/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9122 - sparse_categorical_accuracy: 0.6330 - val_loss: 0.8333 - val_sparse_categorical_accuracy: 0.6668\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.81832\n",
      "Epoch 152/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9144 - sparse_categorical_accuracy: 0.6240 - val_loss: 0.8030 - val_sparse_categorical_accuracy: 0.6840\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.81832 to 0.80302, saving model to checkpoints\\152-0.684.hdf5\n",
      "Epoch 153/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9150 - sparse_categorical_accuracy: 0.6137 - val_loss: 0.7957 - val_sparse_categorical_accuracy: 0.6933\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.80302 to 0.79565, saving model to checkpoints\\153-0.693.hdf5\n",
      "Epoch 154/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9214 - sparse_categorical_accuracy: 0.6181 - val_loss: 0.8339 - val_sparse_categorical_accuracy: 0.6651\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.79565\n",
      "Epoch 155/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9240 - sparse_categorical_accuracy: 0.6205 - val_loss: 0.8257 - val_sparse_categorical_accuracy: 0.6705\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.79565\n",
      "Epoch 156/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9110 - sparse_categorical_accuracy: 0.6227 - val_loss: 0.8357 - val_sparse_categorical_accuracy: 0.6622\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.79565\n",
      "Epoch 157/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.9078 - sparse_categorical_accuracy: 0.6289 - val_loss: 0.8037 - val_sparse_categorical_accuracy: 0.6845\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.79565\n",
      "Epoch 158/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.8991 - sparse_categorical_accuracy: 0.6328 - val_loss: 0.8128 - val_sparse_categorical_accuracy: 0.6774\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.79565\n",
      "Epoch 159/500\n",
      "4082/4082 [==============================] - 31s 8ms/step - loss: 0.9034 - sparse_categorical_accuracy: 0.6247 - val_loss: 0.8444 - val_sparse_categorical_accuracy: 0.6590\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.79565\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.8695 - sparse_categorical_accuracy: 0.6445 - val_loss: 0.8022 - val_sparse_categorical_accuracy: 0.6818\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.77438\n",
      "Epoch 162/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.9004 - sparse_categorical_accuracy: 0.6399 - val_loss: 0.8171 - val_sparse_categorical_accuracy: 0.6769\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.77438\n",
      "Epoch 163/500\n",
      "4082/4082 [==============================] - 2495s 611ms/step - loss: 0.8855 - sparse_categorical_accuracy: 0.6414 - val_loss: 0.7886 - val_sparse_categorical_accuracy: 0.6906\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.77438\n",
      "Epoch 164/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8844 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.8129 - val_sparse_categorical_accuracy: 0.6727\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.77438\n",
      "Epoch 165/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8904 - sparse_categorical_accuracy: 0.6367 - val_loss: 0.7812 - val_sparse_categorical_accuracy: 0.7011\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.77438\n",
      "Epoch 166/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8805 - sparse_categorical_accuracy: 0.6499 - val_loss: 0.7888 - val_sparse_categorical_accuracy: 0.6943\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.77438\n",
      "Epoch 167/500\n",
      "4082/4082 [==============================] - 20s 5ms/step - loss: 0.8893 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.7595 - val_sparse_categorical_accuracy: 0.7077\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.77438 to 0.75949, saving model to checkpoints\\167-0.708.hdf5\n",
      "Epoch 168/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.8743 - sparse_categorical_accuracy: 0.6480 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.6911\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.75949\n",
      "Epoch 169/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8850 - sparse_categorical_accuracy: 0.6414 - val_loss: 0.7760 - val_sparse_categorical_accuracy: 0.6903\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.75949\n",
      "Epoch 170/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.8762 - sparse_categorical_accuracy: 0.6487 - val_loss: 0.7795 - val_sparse_categorical_accuracy: 0.6913\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.75949\n",
      "Epoch 171/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8707 - sparse_categorical_accuracy: 0.6440 - val_loss: 0.7619 - val_sparse_categorical_accuracy: 0.7006\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.75949\n",
      "Epoch 172/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8772 - sparse_categorical_accuracy: 0.6384 - val_loss: 0.7501 - val_sparse_categorical_accuracy: 0.7141\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.75949 to 0.75009, saving model to checkpoints\\172-0.714.hdf5\n",
      "Epoch 173/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.8769 - sparse_categorical_accuracy: 0.6458 - val_loss: 0.7737 - val_sparse_categorical_accuracy: 0.6994\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.75009\n",
      "Epoch 174/500\n",
      "4082/4082 [==============================] - 24s 6ms/step - loss: 0.8619 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.7709 - val_sparse_categorical_accuracy: 0.7070\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.75009\n",
      "Epoch 175/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8536 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.7957 - val_sparse_categorical_accuracy: 0.6877\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.75009\n",
      "Epoch 176/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.8618 - sparse_categorical_accuracy: 0.6529 - val_loss: 0.7657 - val_sparse_categorical_accuracy: 0.6982\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.75009\n",
      "Epoch 177/500\n",
      "4082/4082 [==============================] - 22s 5ms/step - loss: 0.8637 - sparse_categorical_accuracy: 0.6494 - val_loss: 0.7389 - val_sparse_categorical_accuracy: 0.7156\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.75009 to 0.73889, saving model to checkpoints\\177-0.716.hdf5\n",
      "Epoch 178/500\n",
      "4082/4082 [==============================] - 18s 5ms/step - loss: 0.8617 - sparse_categorical_accuracy: 0.6485 - val_loss: 0.7392 - val_sparse_categorical_accuracy: 0.7166\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.73889\n",
      "Epoch 179/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8406 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.7038\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.73889\n",
      "Epoch 180/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.8490 - sparse_categorical_accuracy: 0.6536 - val_loss: 0.7650 - val_sparse_categorical_accuracy: 0.7095\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.73889\n",
      "Epoch 181/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.8449 - sparse_categorical_accuracy: 0.6583 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.7175\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.73889 to 0.73187, saving model to checkpoints\\181-0.718.hdf5\n",
      "Epoch 182/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8494 - sparse_categorical_accuracy: 0.6600 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.7205\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.73187 to 0.72063, saving model to checkpoints\\182-0.720.hdf5\n",
      "Epoch 183/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8333 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.7159 - val_sparse_categorical_accuracy: 0.7266\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.72063 to 0.71592, saving model to checkpoints\\183-0.727.hdf5\n",
      "Epoch 184/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8389 - sparse_categorical_accuracy: 0.6580 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.7058\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.71592\n",
      "Epoch 185/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8415 - sparse_categorical_accuracy: 0.6587 - val_loss: 0.7474 - val_sparse_categorical_accuracy: 0.7114\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.71592\n",
      "Epoch 186/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8482 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.7765 - val_sparse_categorical_accuracy: 0.6889\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.71592\n",
      "Epoch 187/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8280 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.7163\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.71592\n",
      "Epoch 188/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8337 - sparse_categorical_accuracy: 0.6666 - val_loss: 0.7358 - val_sparse_categorical_accuracy: 0.7163\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.71592\n",
      "Epoch 189/500\n",
      "4082/4082 [==============================] - 23s 6ms/step - loss: 0.8249 - sparse_categorical_accuracy: 0.6725 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.7268\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.71592 to 0.70754, saving model to checkpoints\\189-0.727.hdf5\n",
      "Epoch 190/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.8402 - sparse_categorical_accuracy: 0.6563 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.70754\n",
      "Epoch 191/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8269 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.7251\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.70754\n",
      "Epoch 192/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8216 - sparse_categorical_accuracy: 0.6681 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7242\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.70754\n",
      "Epoch 193/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.8164 - sparse_categorical_accuracy: 0.6639 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.7357\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.70754 to 0.70127, saving model to checkpoints\\193-0.736.hdf5\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.8372 - sparse_categorical_accuracy: 0.6639 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.7369\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.70127 to 0.69357, saving model to checkpoints\\194-0.737.hdf5\n",
      "Epoch 195/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8206 - sparse_categorical_accuracy: 0.6668 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.7347\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.69357 to 0.68527, saving model to checkpoints\\195-0.735.hdf5\n",
      "Epoch 196/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.8220 - sparse_categorical_accuracy: 0.6737 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.7286\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.68527\n",
      "Epoch 197/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.8209 - sparse_categorical_accuracy: 0.6634 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.7298\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.68527\n",
      "Epoch 198/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8051 - sparse_categorical_accuracy: 0.6771 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.7246\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.68527\n",
      "Epoch 199/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8114 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.7364\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.68527\n",
      "Epoch 200/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.8163 - sparse_categorical_accuracy: 0.6695 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.7308\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.68527\n",
      "Epoch 201/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.7912 - sparse_categorical_accuracy: 0.6840 - val_loss: 0.7669 - val_sparse_categorical_accuracy: 0.7001\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.68527\n",
      "Epoch 202/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8072 - sparse_categorical_accuracy: 0.6805 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.7342\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.68527\n",
      "Epoch 203/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.8031 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.7614\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.68527 to 0.65543, saving model to checkpoints\\203-0.761.hdf5\n",
      "Epoch 204/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7941 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.7376\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.65543\n",
      "Epoch 205/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.8059 - sparse_categorical_accuracy: 0.6788 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.7455\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.65543\n",
      "Epoch 206/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7954 - sparse_categorical_accuracy: 0.6837 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.7347\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.65543\n",
      "Epoch 207/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.8135 - sparse_categorical_accuracy: 0.6752 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.7499\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.65543\n",
      "Epoch 208/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.7976 - sparse_categorical_accuracy: 0.6786 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.7445\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.65543\n",
      "Epoch 209/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.6600 - val_sparse_categorical_accuracy: 0.7565\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.65543\n",
      "Epoch 210/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.7954 - sparse_categorical_accuracy: 0.6766 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7562\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.65543\n",
      "Epoch 211/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.7896 - sparse_categorical_accuracy: 0.6847 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.65543\n",
      "Epoch 212/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.7975 - sparse_categorical_accuracy: 0.6864 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.7482\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.65543\n",
      "Epoch 213/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.6818 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.7464\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.65543\n",
      "Epoch 214/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.7785 - sparse_categorical_accuracy: 0.6894 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.65543\n",
      "Epoch 215/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7831 - sparse_categorical_accuracy: 0.6894 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.7460\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.65543\n",
      "Epoch 216/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7888 - sparse_categorical_accuracy: 0.6847 - val_loss: 0.6426 - val_sparse_categorical_accuracy: 0.7592\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.65543 to 0.64261, saving model to checkpoints\\216-0.759.hdf5\n",
      "Epoch 217/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.7686 - sparse_categorical_accuracy: 0.6916 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.7521\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.64261\n",
      "Epoch 218/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7597 - sparse_categorical_accuracy: 0.6874 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.7433\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.64261\n",
      "Epoch 219/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7751 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.6360 - val_sparse_categorical_accuracy: 0.7629\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.64261 to 0.63601, saving model to checkpoints\\219-0.763.hdf5\n",
      "Epoch 220/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7544 - sparse_categorical_accuracy: 0.6989 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.7555\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.63601\n",
      "Epoch 221/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.7622 - sparse_categorical_accuracy: 0.6945 - val_loss: 0.6216 - val_sparse_categorical_accuracy: 0.7692\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.63601 to 0.62161, saving model to checkpoints\\221-0.769.hdf5\n",
      "Epoch 222/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7709 - sparse_categorical_accuracy: 0.6938 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.7484\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.62161\n",
      "Epoch 223/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7611 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.7611\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.62161\n",
      "Epoch 224/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7745 - sparse_categorical_accuracy: 0.6955 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.7423\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.62161\n",
      "Epoch 225/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7500 - sparse_categorical_accuracy: 0.6982 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.7634\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.62161\n",
      "Epoch 226/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7668 - sparse_categorical_accuracy: 0.6938 - val_loss: 0.6187 - val_sparse_categorical_accuracy: 0.7709\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.62161 to 0.61870, saving model to checkpoints\\226-0.771.hdf5\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7425 - sparse_categorical_accuracy: 0.7058 - val_loss: 0.6189 - val_sparse_categorical_accuracy: 0.7668\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.61870\n",
      "Epoch 228/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7465 - sparse_categorical_accuracy: 0.7041 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.7729\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.61870 to 0.60515, saving model to checkpoints\\228-0.773.hdf5\n",
      "Epoch 229/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.7621 - sparse_categorical_accuracy: 0.6967 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.7709\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.60515\n",
      "Epoch 230/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7431 - sparse_categorical_accuracy: 0.6997 - val_loss: 0.6067 - val_sparse_categorical_accuracy: 0.7783\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.60515\n",
      "Epoch 231/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7457 - sparse_categorical_accuracy: 0.7011 - val_loss: 0.6095 - val_sparse_categorical_accuracy: 0.7744\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.60515\n",
      "Epoch 232/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.7415 - sparse_categorical_accuracy: 0.7092 - val_loss: 0.6111 - val_sparse_categorical_accuracy: 0.7697\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.60515\n",
      "Epoch 233/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.7528 - sparse_categorical_accuracy: 0.6977 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.7776\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.60515\n",
      "Epoch 234/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7417 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.7619\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.60515\n",
      "Epoch 235/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7462 - sparse_categorical_accuracy: 0.7080 - val_loss: 0.5775 - val_sparse_categorical_accuracy: 0.7861\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.60515 to 0.57749, saving model to checkpoints\\235-0.786.hdf5\n",
      "Epoch 236/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7332 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.6182 - val_sparse_categorical_accuracy: 0.7638\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.57749\n",
      "Epoch 237/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7327 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.5925 - val_sparse_categorical_accuracy: 0.7829\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.57749\n",
      "Epoch 238/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7366 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.7820\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.57749\n",
      "Epoch 239/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7337 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.6120 - val_sparse_categorical_accuracy: 0.7734\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.57749\n",
      "Epoch 240/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7501 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.7827\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.57749\n",
      "Epoch 241/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.7287 - sparse_categorical_accuracy: 0.7117 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7780\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.57749\n",
      "Epoch 242/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7319 - sparse_categorical_accuracy: 0.7099 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.7340\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.57749\n",
      "Epoch 243/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.7464 - sparse_categorical_accuracy: 0.6982 - val_loss: 0.5818 - val_sparse_categorical_accuracy: 0.7815\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.57749\n",
      "Epoch 244/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.7195 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.7866\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.57749\n",
      "Epoch 245/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.7322 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7920\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.57749 to 0.55660, saving model to checkpoints\\245-0.792.hdf5\n",
      "Epoch 246/500\n",
      "4082/4082 [==============================] - 17s 4ms/step - loss: 0.7090 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.7913\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.55660\n",
      "Epoch 247/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7231 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.5673 - val_sparse_categorical_accuracy: 0.7864\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.55660\n",
      "Epoch 248/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7125 - sparse_categorical_accuracy: 0.7190 - val_loss: 0.5845 - val_sparse_categorical_accuracy: 0.7883\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.55660\n",
      "Epoch 249/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7129 - sparse_categorical_accuracy: 0.7180 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.7937\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.55660\n",
      "Epoch 250/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7128 - sparse_categorical_accuracy: 0.7126 - val_loss: 0.5448 - val_sparse_categorical_accuracy: 0.8023\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.55660 to 0.54479, saving model to checkpoints\\250-0.802.hdf5\n",
      "Epoch 251/500\n",
      "4082/4082 [==============================] - 20s 5ms/step - loss: 0.7167 - sparse_categorical_accuracy: 0.7124 - val_loss: 0.5916 - val_sparse_categorical_accuracy: 0.7788\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.54479\n",
      "Epoch 252/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.7131 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.7675\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.54479\n",
      "Epoch 253/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7225 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.5663 - val_sparse_categorical_accuracy: 0.7874\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.54479\n",
      "Epoch 254/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.7099 - sparse_categorical_accuracy: 0.7185 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.7925\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.54479\n",
      "Epoch 255/500\n",
      "4082/4082 [==============================] - 23s 6ms/step - loss: 0.7197 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.7908\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.54479\n",
      "Epoch 256/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.7044 - sparse_categorical_accuracy: 0.7190 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.7861\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.54479\n",
      "Epoch 257/500\n",
      "4082/4082 [==============================] - 19s 5ms/step - loss: 0.7052 - sparse_categorical_accuracy: 0.7180 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7896\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.54479\n",
      "Epoch 258/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6903 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.5584 - val_sparse_categorical_accuracy: 0.7903\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.54479\n",
      "Epoch 259/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.7976\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.54479\n",
      "Epoch 260/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.6843 - sparse_categorical_accuracy: 0.7291 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00260: val_loss did not improve from 0.54479\n",
      "Epoch 261/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7856\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.54479\n",
      "Epoch 262/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.7291 - val_loss: 0.5616 - val_sparse_categorical_accuracy: 0.7923\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.54479\n",
      "Epoch 263/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.7030 - sparse_categorical_accuracy: 0.7185 - val_loss: 0.5318 - val_sparse_categorical_accuracy: 0.8055\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.54479 to 0.53183, saving model to checkpoints\\263-0.805.hdf5\n",
      "Epoch 264/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.6842 - sparse_categorical_accuracy: 0.7251 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.8025\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.53183\n",
      "Epoch 265/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.7002 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.5394 - val_sparse_categorical_accuracy: 0.8021\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.53183\n",
      "Epoch 266/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.6793 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.5742 - val_sparse_categorical_accuracy: 0.7847\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.53183\n",
      "Epoch 267/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6734 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.8060\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.53183\n",
      "Epoch 268/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6948 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.8087\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.53183 to 0.52830, saving model to checkpoints\\268-0.809.hdf5\n",
      "Epoch 269/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.7707\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.52830\n",
      "Epoch 270/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6642 - sparse_categorical_accuracy: 0.7413 - val_loss: 0.5605 - val_sparse_categorical_accuracy: 0.7901\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.52830\n",
      "Epoch 271/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6753 - sparse_categorical_accuracy: 0.7286 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.8025\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.52830\n",
      "Epoch 272/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.5098 - val_sparse_categorical_accuracy: 0.8150\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.52830 to 0.50976, saving model to checkpoints\\272-0.815.hdf5\n",
      "Epoch 273/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.5227 - val_sparse_categorical_accuracy: 0.8111\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.50976\n",
      "Epoch 274/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7261 - val_loss: 0.5371 - val_sparse_categorical_accuracy: 0.8006\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.50976\n",
      "Epoch 275/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6690 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.8094\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.50976\n",
      "Epoch 276/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7261 - val_loss: 0.5300 - val_sparse_categorical_accuracy: 0.8094\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.50976\n",
      "Epoch 277/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.5224 - val_sparse_categorical_accuracy: 0.8121\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.50976\n",
      "Epoch 278/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6631 - sparse_categorical_accuracy: 0.7357 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.8138\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.50976 to 0.50955, saving model to checkpoints\\278-0.814.hdf5\n",
      "Epoch 279/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6721 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.7935\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.50955\n",
      "Epoch 280/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6758 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.7839\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.50955\n",
      "Epoch 281/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6551 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.5183 - val_sparse_categorical_accuracy: 0.8097\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.50955\n",
      "Epoch 282/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.5262 - val_sparse_categorical_accuracy: 0.8087\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.50955\n",
      "Epoch 283/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6635 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8153\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.50955 to 0.50882, saving model to checkpoints\\283-0.815.hdf5\n",
      "Epoch 284/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6617 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.5060 - val_sparse_categorical_accuracy: 0.8126\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.50882 to 0.50601, saving model to checkpoints\\284-0.813.hdf5\n",
      "Epoch 285/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.7398 - val_loss: 0.5121 - val_sparse_categorical_accuracy: 0.8097\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.50601\n",
      "Epoch 286/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6661 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.7871\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.50601\n",
      "Epoch 287/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7440 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.8030\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.50601\n",
      "Epoch 288/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.8035\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.50601\n",
      "Epoch 289/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6576 - sparse_categorical_accuracy: 0.7389 - val_loss: 0.4829 - val_sparse_categorical_accuracy: 0.8268\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.50601 to 0.48288, saving model to checkpoints\\289-0.827.hdf5\n",
      "Epoch 290/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6569 - sparse_categorical_accuracy: 0.7391 - val_loss: 0.5067 - val_sparse_categorical_accuracy: 0.8190\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.48288\n",
      "Epoch 291/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.8297e_categorical_accu\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.48288 to 0.47752, saving model to checkpoints\\291-0.830.hdf5\n",
      "Epoch 292/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.6557 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8393\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.47752 to 0.47061, saving model to checkpoints\\292-0.839.hdf5\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.7438 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.8256\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.47061\n",
      "Epoch 294/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6320 - sparse_categorical_accuracy: 0.7570 - val_loss: 0.4822 - val_sparse_categorical_accuracy: 0.8253\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.47061\n",
      "Epoch 295/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.5082 - val_sparse_categorical_accuracy: 0.8097\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.47061\n",
      "Epoch 296/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6390 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8344\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.47061 to 0.45927, saving model to checkpoints\\296-0.834.hdf5\n",
      "Epoch 297/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6318 - sparse_categorical_accuracy: 0.7455 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.8246\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.45927\n",
      "Epoch 298/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6544 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.4890 - val_sparse_categorical_accuracy: 0.8224\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.45927\n",
      "Epoch 299/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.7479 - val_loss: 0.4744 - val_sparse_categorical_accuracy: 0.8315\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.45927\n",
      "Epoch 300/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6388 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.4793 - val_sparse_categorical_accuracy: 0.8256\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.45927\n",
      "Epoch 301/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8082\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.45927\n",
      "Epoch 302/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6359 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8378\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.45927 to 0.45341, saving model to checkpoints\\302-0.838.hdf5\n",
      "Epoch 303/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6345 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.8293\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.45341\n",
      "Epoch 304/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6357 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.4748 - val_sparse_categorical_accuracy: 0.8275\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.45341\n",
      "Epoch 305/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6248 - sparse_categorical_accuracy: 0.7545 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8386\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.45341\n",
      "Epoch 306/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6228 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.4734 - val_sparse_categorical_accuracy: 0.8307\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.45341\n",
      "Epoch 307/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6438 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.8315\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.45341\n",
      "Epoch 308/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6142 - sparse_categorical_accuracy: 0.7592 - val_loss: 0.4609 - val_sparse_categorical_accuracy: 0.8319\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.45341\n",
      "Epoch 309/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6223 - sparse_categorical_accuracy: 0.7565 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.8332\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.45341\n",
      "Epoch 310/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8491\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.45341 to 0.44124, saving model to checkpoints\\310-0.849.hdf5\n",
      "Epoch 311/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6171 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.5047 - val_sparse_categorical_accuracy: 0.8172\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.44124\n",
      "Epoch 312/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.4952 - val_sparse_categorical_accuracy: 0.8141\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.44124\n",
      "Epoch 313/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.7567 - val_loss: 0.4435 - val_sparse_categorical_accuracy: 0.8435\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.44124\n",
      "Epoch 314/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8469\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.44124 to 0.43594, saving model to checkpoints\\314-0.847.hdf5\n",
      "Epoch 315/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.7548 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.8405\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.43594\n",
      "Epoch 316/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6022 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8437\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.43594\n",
      "Epoch 317/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6279 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.8469\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.43594\n",
      "Epoch 318/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5975 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.4508 - val_sparse_categorical_accuracy: 0.8366\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.43594\n",
      "Epoch 319/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8214\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.43594\n",
      "Epoch 320/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6179 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.8305\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.43594\n",
      "Epoch 321/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.6014 - sparse_categorical_accuracy: 0.7643 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8457\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.43594 to 0.43562, saving model to checkpoints\\321-0.846.hdf5\n",
      "Epoch 322/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5981 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.8417\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.43562 to 0.43421, saving model to checkpoints\\322-0.842.hdf5\n",
      "Epoch 323/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6042 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8346\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.43421\n",
      "Epoch 324/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.6038 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.8420\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.43421 to 0.42732, saving model to checkpoints\\324-0.842.hdf5\n",
      "Epoch 325/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8354\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.42732\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.4339 - val_sparse_categorical_accuracy: 0.8403\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.42732\n",
      "Epoch 327/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5900 - sparse_categorical_accuracy: 0.7658 - val_loss: 0.4117 - val_sparse_categorical_accuracy: 0.8555\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.42732 to 0.41172, saving model to checkpoints\\327-0.855.hdf5\n",
      "Epoch 328/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.5895 - sparse_categorical_accuracy: 0.7739 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.8560\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.41172 to 0.40287, saving model to checkpoints\\328-0.856.hdf5\n",
      "Epoch 329/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5873 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.4082 - val_sparse_categorical_accuracy: 0.8584\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.40287\n",
      "Epoch 330/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.4456 - val_sparse_categorical_accuracy: 0.8359\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.40287\n",
      "Epoch 331/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5823 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.3980 - val_sparse_categorical_accuracy: 0.8599\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.40287 to 0.39796, saving model to checkpoints\\331-0.860.hdf5\n",
      "Epoch 332/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.7732 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8390\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.39796\n",
      "Epoch 333/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5795 - sparse_categorical_accuracy: 0.7712 - val_loss: 0.4124 - val_sparse_categorical_accuracy: 0.8511\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.39796\n",
      "Epoch 334/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5758 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.4037 - val_sparse_categorical_accuracy: 0.8584\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.39796\n",
      "Epoch 335/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.4057 - val_sparse_categorical_accuracy: 0.8586\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.39796\n",
      "Epoch 336/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7697 - val_loss: 0.4112 - val_sparse_categorical_accuracy: 0.8601\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.39796\n",
      "Epoch 337/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5741 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.4293 - val_sparse_categorical_accuracy: 0.8452\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.39796\n",
      "Epoch 338/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5733 - sparse_categorical_accuracy: 0.7746 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8462\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.39796\n",
      "Epoch 339/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.7580 - val_loss: 0.4239 - val_sparse_categorical_accuracy: 0.8498\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.39796\n",
      "Epoch 340/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5835 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8364\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.39796\n",
      "Epoch 341/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.3904 - val_sparse_categorical_accuracy: 0.8626\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.39796 to 0.39038, saving model to checkpoints\\341-0.863.hdf5\n",
      "Epoch 342/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8457\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.39038\n",
      "Epoch 343/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5599 - sparse_categorical_accuracy: 0.7827 - val_loss: 0.4261 - val_sparse_categorical_accuracy: 0.8422\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.39038\n",
      "Epoch 344/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5858 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8474\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.39038\n",
      "Epoch 345/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8275\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.39038\n",
      "Epoch 346/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5816 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.3975 - val_sparse_categorical_accuracy: 0.8609\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.39038\n",
      "Epoch 347/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.5668 - sparse_categorical_accuracy: 0.7852 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8417\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.39038\n",
      "Epoch 348/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.7761 - val_loss: 0.3726 - val_sparse_categorical_accuracy: 0.8758\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.39038 to 0.37260, saving model to checkpoints\\348-0.876.hdf5\n",
      "Epoch 349/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5579 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8645\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.37260\n",
      "Epoch 350/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5515 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.4074 - val_sparse_categorical_accuracy: 0.8545\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.37260\n",
      "Epoch 351/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5756 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8658\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.37260\n",
      "Epoch 352/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.8628\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.37260\n",
      "Epoch 353/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 0.8672\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.37260\n",
      "Epoch 354/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.3820 - val_sparse_categorical_accuracy: 0.8677\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.37260\n",
      "Epoch 355/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5673 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8439\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.37260\n",
      "Epoch 356/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.7793 - val_loss: 0.4004 - val_sparse_categorical_accuracy: 0.8540\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.37260\n",
      "Epoch 357/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7820 - val_loss: 0.4003 - val_sparse_categorical_accuracy: 0.8542\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.37260\n",
      "Epoch 358/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5413 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.8376\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.37260\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.8655\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.37260\n",
      "Epoch 360/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5403 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.3719 - val_sparse_categorical_accuracy: 0.8689\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.37260 to 0.37193, saving model to checkpoints\\360-0.869.hdf5\n",
      "Epoch 361/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7783 - val_loss: 0.3859 - val_sparse_categorical_accuracy: 0.8667\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.37193\n",
      "Epoch 362/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.3984 - val_sparse_categorical_accuracy: 0.8626\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.37193\n",
      "Epoch 363/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5512 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.3988 - val_sparse_categorical_accuracy: 0.8621\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.37193\n",
      "Epoch 364/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8452\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.37193\n",
      "Epoch 365/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5688 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.4001 - val_sparse_categorical_accuracy: 0.8618\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.37193\n",
      "Epoch 366/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.3805 - val_sparse_categorical_accuracy: 0.8687\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.37193\n",
      "Epoch 367/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8733\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.37193 to 0.37155, saving model to checkpoints\\367-0.873.hdf5\n",
      "Epoch 368/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.5594 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.3495 - val_sparse_categorical_accuracy: 0.8844\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.37155 to 0.34945, saving model to checkpoints\\368-0.884.hdf5\n",
      "Epoch 369/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5433 - sparse_categorical_accuracy: 0.7901 - val_loss: 0.3698 - val_sparse_categorical_accuracy: 0.8699\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.34945\n",
      "Epoch 370/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.3552 - val_sparse_categorical_accuracy: 0.8787\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.34945\n",
      "Epoch 371/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.3645 - val_sparse_categorical_accuracy: 0.8768\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.34945\n",
      "Epoch 372/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5383 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.3772 - val_sparse_categorical_accuracy: 0.8682\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.34945\n",
      "Epoch 373/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7878 - val_loss: 0.4001 - val_sparse_categorical_accuracy: 0.8638\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.34945\n",
      "Epoch 374/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5396 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.3588 - val_sparse_categorical_accuracy: 0.8785\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.34945\n",
      "Epoch 375/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5347 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8633\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.34945\n",
      "Epoch 376/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.3545 - val_sparse_categorical_accuracy: 0.8746\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.34945\n",
      "Epoch 377/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5368 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.3560 - val_sparse_categorical_accuracy: 0.8751\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.34945\n",
      "Epoch 378/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5324 - sparse_categorical_accuracy: 0.7927 - val_loss: 0.3569 - val_sparse_categorical_accuracy: 0.8736\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.34945\n",
      "Epoch 379/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5138 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.3606 - val_sparse_categorical_accuracy: 0.8770\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.34945\n",
      "Epoch 380/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5332 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.34945 to 0.33931, saving model to checkpoints\\380-0.890.hdf5\n",
      "Epoch 381/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.7898 - val_loss: 0.3635 - val_sparse_categorical_accuracy: 0.87820s - loss: 0.5515 - sparse_categorical_accuracy: 0.\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.33931\n",
      "Epoch 382/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5351 - sparse_categorical_accuracy: 0.7952 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.8834\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.33931\n",
      "Epoch 383/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.5076 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.3772 - val_sparse_categorical_accuracy: 0.8684\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.33931\n",
      "Epoch 384/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5366 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.8812\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.33931\n",
      "Epoch 385/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5240 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.3401 - val_sparse_categorical_accuracy: 0.8878\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.33931\n",
      "Epoch 386/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.3527 - val_sparse_categorical_accuracy: 0.8836\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.33931\n",
      "Epoch 387/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5334 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.3290 - val_sparse_categorical_accuracy: 0.8942\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.33931 to 0.32896, saving model to checkpoints\\387-0.894.hdf5\n",
      "Epoch 388/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8834\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.32896\n",
      "Epoch 389/500\n",
      "4082/4082 [==============================] - 18s 4ms/step - loss: 0.5224 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.3272 - val_sparse_categorical_accuracy: 0.8937\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.32896 to 0.32718, saving model to checkpoints\\389-0.894.hdf5\n",
      "Epoch 390/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5167 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.3730 - val_sparse_categorical_accuracy: 0.8692\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.32718\n",
      "Epoch 391/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5248 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.8851\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.32718\n",
      "Epoch 392/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5241 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.3673 - val_sparse_categorical_accuracy: 0.8721\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.32718\n",
      "Epoch 393/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5212 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.3375 - val_sparse_categorical_accuracy: 0.8858\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.32718\n",
      "Epoch 394/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5247 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.3147 - val_sparse_categorical_accuracy: 0.8949\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.32718 to 0.31468, saving model to checkpoints\\394-0.895.hdf5\n",
      "Epoch 395/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5096 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8623\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.31468\n",
      "Epoch 396/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5163 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.3267 - val_sparse_categorical_accuracy: 0.8932\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.31468\n",
      "Epoch 397/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.8954\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.31468\n",
      "Epoch 398/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.3111 - val_sparse_categorical_accuracy: 0.9013\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.31468 to 0.31108, saving model to checkpoints\\398-0.901.hdf5\n",
      "Epoch 399/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4925 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.3318 - val_sparse_categorical_accuracy: 0.8878\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.31108\n",
      "Epoch 400/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8626\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.31108\n",
      "Epoch 401/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5094 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.3729 - val_sparse_categorical_accuracy: 0.8711\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.31108\n",
      "Epoch 402/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.8038 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8819\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.31108\n",
      "Epoch 403/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5116 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.3607 - val_sparse_categorical_accuracy: 0.8756\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.31108\n",
      "Epoch 404/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.3323 - val_sparse_categorical_accuracy: 0.8880\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.31108\n",
      "Epoch 405/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4908 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8834\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.31108\n",
      "Epoch 406/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4889 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.8770\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.31108\n",
      "Epoch 407/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4974 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.3385 - val_sparse_categorical_accuracy: 0.8858\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.31108\n",
      "Epoch 408/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.5013 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.3236 - val_sparse_categorical_accuracy: 0.8912\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.31108\n",
      "Epoch 409/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4883 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.3145 - val_sparse_categorical_accuracy: 0.8969\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.31108\n",
      "Epoch 410/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4934 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.2927 - val_sparse_categorical_accuracy: 0.9023\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.31108 to 0.29266, saving model to checkpoints\\410-0.902.hdf5\n",
      "Epoch 411/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4968 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.3228 - val_sparse_categorical_accuracy: 0.8895\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.29266\n",
      "Epoch 412/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4808 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.2882 - val_sparse_categorical_accuracy: 0.9069\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.29266 to 0.28816, saving model to checkpoints\\412-0.907.hdf5\n",
      "Epoch 413/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4964 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.3037 - val_sparse_categorical_accuracy: 0.8991\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.28816\n",
      "Epoch 414/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.5067 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.8895\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.28816\n",
      "Epoch 415/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4876 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.3242 - val_sparse_categorical_accuracy: 0.8893\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.28816\n",
      "Epoch 416/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4881 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.8932\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.28816\n",
      "Epoch 417/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4712 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8983\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.28816\n",
      "Epoch 418/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4858 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.3063 - val_sparse_categorical_accuracy: 0.9010\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.28816\n",
      "Epoch 419/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4887 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.2928 - val_sparse_categorical_accuracy: 0.9079\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.28816\n",
      "Epoch 420/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.3183 - val_sparse_categorical_accuracy: 0.8917\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.28816\n",
      "Epoch 421/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4837 - sparse_categorical_accuracy: 0.8180 - val_loss: 0.3371 - val_sparse_categorical_accuracy: 0.8824\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.28816\n",
      "Epoch 422/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4890 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.3194 - val_sparse_categorical_accuracy: 0.8890\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.28816\n",
      "Epoch 423/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.3024 - val_sparse_categorical_accuracy: 0.9010- loss: 0.4839 - sparse_categorical\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.28816\n",
      "Epoch 424/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4796 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.3203 - val_sparse_categorical_accuracy: 0.8898\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.28816\n",
      "Epoch 425/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4780 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.2966 - val_sparse_categorical_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00425: val_loss did not improve from 0.28816\n",
      "Epoch 426/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4771 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.2913 - val_sparse_categorical_accuracy: 0.9072\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.28816\n",
      "Epoch 427/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8996\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.28816\n",
      "Epoch 428/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.8180 - val_loss: 0.2958 - val_sparse_categorical_accuracy: 0.9015\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.28816\n",
      "Epoch 429/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4608 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.9138\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.28816 to 0.28269, saving model to checkpoints\\429-0.914.hdf5\n",
      "Epoch 430/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4815 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.8876\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.28269\n",
      "Epoch 431/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.2721 - val_sparse_categorical_accuracy: 0.9160\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.28269 to 0.27212, saving model to checkpoints\\431-0.916.hdf5\n",
      "Epoch 432/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.2828 - val_sparse_categorical_accuracy: 0.9118\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.27212\n",
      "Epoch 433/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4594 - sparse_categorical_accuracy: 0.8256 - val_loss: 0.2888 - val_sparse_categorical_accuracy: 0.9079\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.27212\n",
      "Epoch 434/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4789 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.8959\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.27212\n",
      "Epoch 435/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4738 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.3060 - val_sparse_categorical_accuracy: 0.9015\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.27212\n",
      "Epoch 436/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4743 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.3550 - val_sparse_categorical_accuracy: 0.8714\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.27212\n",
      "Epoch 437/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4594 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.2959 - val_sparse_categorical_accuracy: 0.9049\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.27212\n",
      "Epoch 438/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.4813 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.8895\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.27212\n",
      "Epoch 439/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4610 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.2731 - val_sparse_categorical_accuracy: 0.9150\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.27212\n",
      "Epoch 440/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4795 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.3185 - val_sparse_categorical_accuracy: 0.8988\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.27212\n",
      "Epoch 441/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4741 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.3326 - val_sparse_categorical_accuracy: 0.8878\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.27212\n",
      "Epoch 442/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4682 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9194\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.27212 to 0.26804, saving model to checkpoints\\442-0.919.hdf5\n",
      "Epoch 443/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.2804 - val_sparse_categorical_accuracy: 0.9123\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.26804\n",
      "Epoch 444/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4710 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.2715 - val_sparse_categorical_accuracy: 0.9143\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.26804\n",
      "Epoch 445/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4568 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.3056 - val_sparse_categorical_accuracy: 0.8939\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.26804\n",
      "Epoch 446/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4597 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.2747 - val_sparse_categorical_accuracy: 0.9111\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.26804\n",
      "Epoch 447/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.2778 - val_sparse_categorical_accuracy: 0.9111\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.26804\n",
      "Epoch 448/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4478 - sparse_categorical_accuracy: 0.8327 - val_loss: 0.3317 - val_sparse_categorical_accuracy: 0.8819\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.26804\n",
      "Epoch 449/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4621 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.2600 - val_sparse_categorical_accuracy: 0.9211\n",
      "\n",
      "Epoch 00449: val_loss improved from 0.26804 to 0.26003, saving model to checkpoints\\449-0.921.hdf5\n",
      "Epoch 450/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4432 - sparse_categorical_accuracy: 0.8310 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8880\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.26003\n",
      "Epoch 451/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.8180 - val_loss: 0.3236 - val_sparse_categorical_accuracy: 0.8883\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.26003\n",
      "Epoch 452/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4645 - sparse_categorical_accuracy: 0.8209 - val_loss: 0.2951 - val_sparse_categorical_accuracy: 0.9023\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.26003\n",
      "Epoch 453/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.2758 - val_sparse_categorical_accuracy: 0.9089\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.26003\n",
      "Epoch 454/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4641 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.2852 - val_sparse_categorical_accuracy: 0.9084\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.26003\n",
      "Epoch 455/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9113\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.26003\n",
      "Epoch 456/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4633 - sparse_categorical_accuracy: 0.8197 - val_loss: 0.2656 - val_sparse_categorical_accuracy: 0.9160\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.26003\n",
      "Epoch 457/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.2642 - val_sparse_categorical_accuracy: 0.9177\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.26003\n",
      "Epoch 458/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4683 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.2782 - val_sparse_categorical_accuracy: 0.9040\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.26003\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9277\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.26003 to 0.24088, saving model to checkpoints\\459-0.928.hdf5\n",
      "Epoch 460/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.2738 - val_sparse_categorical_accuracy: 0.9094\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.24088\n",
      "Epoch 461/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4640 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9130\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.24088\n",
      "Epoch 462/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4403 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.8824\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.24088\n",
      "Epoch 463/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.2637 - val_sparse_categorical_accuracy: 0.9165\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.24088\n",
      "Epoch 464/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4144 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8633\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.24088\n",
      "Epoch 465/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9194\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.24088\n",
      "Epoch 466/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.24088\n",
      "Epoch 467/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4518 - sparse_categorical_accuracy: 0.8324 - val_loss: 0.2745 - val_sparse_categorical_accuracy: 0.9118\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.24088\n",
      "Epoch 468/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.2644 - val_sparse_categorical_accuracy: 0.9116\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.24088\n",
      "Epoch 469/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4438 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.2526 - val_sparse_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.24088\n",
      "Epoch 470/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8334 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.9020\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.24088\n",
      "Epoch 471/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.2332 - val_sparse_categorical_accuracy: 0.9260\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.24088 to 0.23319, saving model to checkpoints\\471-0.926.hdf5\n",
      "Epoch 472/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.2506 - val_sparse_categorical_accuracy: 0.9179\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.23319\n",
      "Epoch 473/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4150 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.2361 - val_sparse_categorical_accuracy: 0.9255\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.23319\n",
      "Epoch 474/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.2424 - val_sparse_categorical_accuracy: 0.9214\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.23319\n",
      "Epoch 475/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.2414 - val_sparse_categorical_accuracy: 0.9253\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.23319\n",
      "Epoch 476/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4267 - sparse_categorical_accuracy: 0.8410 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9309\n",
      "\n",
      "Epoch 00476: val_loss improved from 0.23319 to 0.22514, saving model to checkpoints\\476-0.931.hdf5\n",
      "Epoch 477/500\n",
      "4082/4082 [==============================] - 16s 4ms/step - loss: 0.4572 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.2782 - val_sparse_categorical_accuracy: 0.9040\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.22514\n",
      "Epoch 478/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.2777 - val_sparse_categorical_accuracy: 0.9030\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.22514\n",
      "Epoch 479/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.2585 - val_sparse_categorical_accuracy: 0.9138\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.22514\n",
      "Epoch 480/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4330 - sparse_categorical_accuracy: 0.8393 - val_loss: 0.2347 - val_sparse_categorical_accuracy: 0.9280\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.22514\n",
      "Epoch 481/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4186 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9162\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.22514\n",
      "Epoch 482/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.2646 - val_sparse_categorical_accuracy: 0.9103\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.22514\n",
      "Epoch 483/500\n",
      "4082/4082 [==============================] - 14s 4ms/step - loss: 0.4230 - sparse_categorical_accuracy: 0.8366 - val_loss: 0.2297 - val_sparse_categorical_accuracy: 0.9275\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.22514\n",
      "Epoch 484/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4384 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9277\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.22514\n",
      "Epoch 485/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4401 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9263\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.22514\n",
      "Epoch 486/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4333 - sparse_categorical_accuracy: 0.8346 - val_loss: 0.2340 - val_sparse_categorical_accuracy: 0.9277\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.22514\n",
      "Epoch 487/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4256 - sparse_categorical_accuracy: 0.8332 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9275\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.22514\n",
      "Epoch 488/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4124 - sparse_categorical_accuracy: 0.8452 - val_loss: 0.2475 - val_sparse_categorical_accuracy: 0.9236\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.22514\n",
      "Epoch 489/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.2308 - val_sparse_categorical_accuracy: 0.9312\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.22514\n",
      "Epoch 490/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4231 - sparse_categorical_accuracy: 0.8425 - val_loss: 0.2300 - val_sparse_categorical_accuracy: 0.9326\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.22514\n",
      "Epoch 491/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9346\n",
      "\n",
      "Epoch 00491: val_loss improved from 0.22514 to 0.21725, saving model to checkpoints\\491-0.935.hdf5\n",
      "Epoch 492/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4244 - sparse_categorical_accuracy: 0.8373 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00492: val_loss did not improve from 0.21725\n",
      "Epoch 493/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4085 - sparse_categorical_accuracy: 0.8417 - val_loss: 0.2154 - val_sparse_categorical_accuracy: 0.9346\n",
      "\n",
      "Epoch 00493: val_loss improved from 0.21725 to 0.21542, saving model to checkpoints\\493-0.935.hdf5\n",
      "Epoch 494/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8344 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9236\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.21542\n",
      "Epoch 495/500\n",
      "4082/4082 [==============================] - 12s 3ms/step - loss: 0.4103 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.2180 - val_sparse_categorical_accuracy: 0.9336\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.21542\n",
      "Epoch 496/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4208 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.2421 - val_sparse_categorical_accuracy: 0.9219\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.21542\n",
      "Epoch 497/500\n",
      "4082/4082 [==============================] - 13s 3ms/step - loss: 0.4207 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.2278 - val_sparse_categorical_accuracy: 0.9285\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.21542\n",
      "Epoch 498/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4198 - sparse_categorical_accuracy: 0.8437 - val_loss: 0.2698 - val_sparse_categorical_accuracy: 0.9118\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.21542\n",
      "Epoch 499/500\n",
      "4082/4082 [==============================] - 15s 4ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.2573 - val_sparse_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.21542\n",
      "Epoch 500/500\n",
      "4082/4082 [==============================] - 14s 3ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8462 - val_loss: 0.2555 - val_sparse_categorical_accuracy: 0.9157\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.21542\n"
     ]
    }
   ],
   "source": [
    "####### Two merged LSTM encoders #####################\n",
    "x_train_a, x_train_b, y_train, x_val_a, x_val_b, y_val = DataTwoStream(\"x_shuffled_0.npy\", \"y_shuffled_0.npy\")\n",
    "data_dim = 1\n",
    "timesteps = x_train.shape[1] #60\n",
    "nb_classes = len(np.unique(y_train)) #5\n",
    "\n",
    "first_input = Input((timesteps, data_dim))\n",
    "encoder_a = LSTM(32, return_sequences=True,\n",
    "                 batch_input_shape=(batch_size,timesteps, data_dim))(first_input)\n",
    "encoder_a = Dropout(0.2)(encoder_a)\n",
    "encoder_a = LSTM(32)(encoder_a)\n",
    "encoder_a_out = Dropout(0.2)(encoder_a)\n",
    "model_a = Model(first_input, encoder_a_out)\n",
    "\n",
    "second_input = Input((timesteps, data_dim))\n",
    "encoder_b = LSTM(32, return_sequences=True,\n",
    "                 batch_input_shape=(batch_size, timesteps, data_dim))(second_input)\n",
    "encoder_b = Dropout(0.2)(encoder_b)\n",
    "encoder_b = LSTM(32)(encoder_b)\n",
    "encoder_b_out = Dropout(0.2)(encoder_b)\n",
    "model_b = Model(second_input, encoder_b_out)\n",
    "\n",
    "concatenated = concatenate([encoder_a_out, encoder_b_out])\n",
    "decoder = Dense(32, activation='relu')(concatenated)\n",
    "output_layer = Dense(nb_classes, activation='softmax')(decoder)\n",
    "\n",
    "model = Model([first_input, second_input], output_layer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "##################################### Helpers in callbacks ##############################################\n",
    "tb = TensorBoard(log_dir=os.path.join('tensorboard', 'logs',))\n",
    "early_stopper = EarlyStopping(patience=20)\n",
    "csv_logger = CSVLogger(os.path.join('logs', str(time.time()) + '.log'))\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join('checkpoints','{epoch:03d}-{val_sparse_categorical_accuracy:.3f}.hdf5'),\n",
    "                                verbose=1,save_best_only=True)\n",
    "history = History()\n",
    "#########################################################################################################\n",
    "hist = model.fit([x_train_a, x_train_b], y_train,\n",
    "            batch_size=64, epochs=500, \n",
    "            validation_data=([x_val_a, x_val_b], y_val),\n",
    "            callbacks=[tb, early_stopper, csv_logger, checkpointer, history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-204d19746b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m####### Single LSTM encoder with two parallel sequences #####################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataTwoStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x_shuffled_0.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_shuffled_0.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Graph'"
     ]
    }
   ],
   "source": [
    "####### Single LSTM encoder with two parallel sequences #####################\n",
    "x_train_a, x_train_b, y_train, x_val_a, x_val_b, y_val = DataTwoStream(\"x_shuffled_0.npy\", \"y_shuffled_0.npy\")\n",
    "data_dim = 1\n",
    "timesteps = x_train.shape[1] #60\n",
    "nb_classes = len(np.unique(y_train)) #5\n",
    "\n",
    "first_input = Input((timesteps, data_dim))\n",
    "second_input = Input((timesteps, data_dim))\n",
    "concatenated = concatenate([first_input, second_input])\n",
    "\n",
    "lstm = LSTM(32, return_sequences=True,\n",
    "                 batch_input_shape=(batch_size, timesteps, data_dim))(concatenated)\n",
    "lstm = Dropout(0.2)(lstm)\n",
    "lstm = LSTM(32)(lstm)\n",
    "lstm = Dropout(0.2)(lstm)\n",
    "dense = Dense(32, activation='relu')(lstm)\n",
    "output_layer = Dense(nb_classes, activation='softmax')(dense)\n",
    "\n",
    "model = Model([first_input, second_input], output_layer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_categorical_accuracy: 93.46%\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"best.hdf5\")\n",
    "loaded_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "score = loaded_model.evaluate([x_val_a, x_val_b], y_val, verbose=0, batch_size = 8)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97      1015\n",
      "         1.0       0.90      0.91      0.90       646\n",
      "         2.0       0.88      0.93      0.91       769\n",
      "         3.0       0.94      0.94      0.94       855\n",
      "         4.0       0.94      0.94      0.94       797\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      4082\n",
      "   macro avg       0.93      0.93      0.93      4082\n",
      "weighted avg       0.94      0.93      0.93      4082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict([x_val_a, x_val_b])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185876c44a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185876c4eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['sparse_categorical_accuracy'])\n",
    "pyplot.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1015\n",
      "         1.0       1.00      1.00      1.00       646\n",
      "         2.0       1.00      1.00      1.00       769\n",
      "         3.0       1.00      1.00      1.00       855\n",
      "         4.0       1.00      1.00      1.00       797\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      4082\n",
      "   macro avg       1.00      1.00      1.00      4082\n",
      "weighted avg       1.00      1.00      1.00      4082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(x_train)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1021, 60, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
